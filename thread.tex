In the previous chapter, we introduced new language facilities that can be used
by the programmer to coordinate execution. While these facilities retain the
implicit parallelism of the language, they do not allow the programmer to fully
reason about the underlying parallel architecture since the only reasoning
allowed relates to node partitioning and movement between threads. In principle,
it should be advantageous to reason about thread state, that is, to perform rule
inference about facts stored on each thread and allow threads to communicate and
coordinate between them depending on their current state. This would introduce a
kind of explicit parallelism into the implicit parallel model of LM.
However, this explicit parallelism should remain declarative in order to be easy
sto prove properties about the thread's state.

\section{Motivational Example: Graph Searching}
\input{threads/graph_reachability}

\section{Implementation Changes}
\input{threads/implementation}

\section{Applications}

This section presents more applications that demonstrate the usefulness and
power of thread-based facts.

\subsection{Binary Search Trees: Caching Results}
\input{threads/key_value}

\subsection{PowerGrid Problem}
\input{threads/powergrid}

\subsection{Splash Belief Propagation}\label{sec:coordination:bp}
\input{threads/splash-bp}

\section{Modeling the Operational Semantics in LM}
\input{threads/modeling}

\section{Related Work}
\input{threads/related_work}

\section{Chapter Summary}
\input{threads/summary}
