Table~\ref{tbl:language:ast} shows the abstract syntax for rules in LM.  A LM
program $Prog$ consists of a list of derivation rules $\Sigma$ and a database
$D$. A database fact $l(\hat{t})$ is an association between a predicate $l$ and
a list of literals $\hat{t}$. Each derivation rule $R$ can be written as $LHS
\lolli RHS$ with the meaning described in
Section~\ref{section:language:message}.  Rules without an LHS are allowed in LM
and they are called \emph{initial facts}
(lines~\ref{line:language:dict_axioms1}-\ref{line:language:dict_axioms2} in
Fig.~\ref{code:language:btree_replace}).

\newcommand{\sop}[0]{\Vert}

\begin{table}[h]
\centering
\begin{tabular}{ l l c l }
  Program & $Prog$ & $::=$ & $\Sigma, D$ \\
  List Of Rules & $\Sigma$ & $::=$ & $\cdot \; \sop \; \Sigma, R$\\
  Database & $D$ & $::=$ & $\Gamma; \Delta$ \\
  Rule & $R$ & $::=$ & $LHS \lolli RHS \; \sop \; \forall_{x}. R \; \sop \;
  \selector{S}{y}{LHS}{RHS}$ \\
  LHS Expression & $LHS$ & $::=$ & $L \; \sop \; P \; \sop \; C \; \sop \; LHS,
  LHS \; \sop \; \exists_{x}. LHS \; \sop \; \one$\\
  RHS Expression & $RHS$ & $::=$ & $L \; \sop \; P \; \sop \; RHS, RHS \; \sop
  \; EE \; \sop \; CE \; \sop \; AE \; \sop \; \one$\\
  
  Linear Atomic Proposition & $L$ & $::=$ & $l(\hat{x})$\\
  Persistent Atomic Prop. & $P$ & $::=$ & $\bang p(\hat{x})$\\
  Constraint & $C$ & $::=$ & $c(\hat{x})$ \\
  Selector Operation & $S$ & $::=$ & $\mathtt{min} \; \sop \; \mathtt{max} \;
  \sop \; \mathtt{random}$\\
  
  Exists Expression & $EE$ & $::=$ & $\existsc{\widehat{x}}{SRHS}$ \\
  Comprehension & $CE$ & $::=$ & $\comprehension{\widehat{x}}{SLHS}{SRHS}$ \\

  Aggregate & $AE$ & $::=$ & $\aggregate{A}{y}{\widehat{x}}{SLHS}{SRHS_1}{SRHS_2}$ \\
  Aggregate Operation & $A$ & $::=$ & $\mathtt{min} \; \sop \; \mathtt{max} \; \sop \;
\mathtt{sum} \; \sop \; \mathtt{count} \; \sop \; \mathtt{collect}$ \\
  
  Sub-LHS & $SLHS$ & $::=$ & $L \; \sop \; P \; \sop \; SLHS, SLHS \; \sop \; \exists_{x}. SLHS$\\
  Sub-RHS & $SRHS$ & $::=$ & $L \; \sop \; P \; \sop \; SRHS, SRHS \; \sop \; \one$\\
  
  Known Linear Facts & $\Delta$ & $::=$ & $\cdot \; \sop \; \Delta, l(\hat{t})$ \\
  Known Persistent Facts & $\Gamma$ & $::=$ & $\cdot \; \sop \; \Gamma, \bang p(\hat{t})$ \\

  Literal List & $\hat{t}$ & $::=$ & $\cdot \; \sop \; t, \hat{t}$ \\
  Term List & $\hat{x}$ & $::=$ & $\cdot \; \sop \; x, \hat{x} \; \sop \; t, \hat{x}$ \\
  Literal & $t$ & $::=$ & $\m{number}(N) \; \sop \; \m{node}(N) \; \sop \; \m{list}(\hat{t}) \; \sop \ldots$ \\
\end{tabular}
\caption{Core abstract syntax of LM.}\label{tbl:language:ast}
\end{table}

The LHS of a rule, $LHS$, may contain linear ($L$) and persistent ($P$)
\emph{atomic propositions} and constraints ($C$). Atomic propositions are
template facts that instantiate variables (from facts in the database) such as
\code{visit(A)} in line~\ref{line:language:visit_second} in
Fig.~\ref{code:language:visit}. Variables can be used again in the LHS for
matching and also in the RHS when instantiating facts.  Constraints are boolean
expressions that must be true in order for the rule to be derived. Constraints
use variables from fact expressions and are built using a small functional
language that includes mathematical operations, boolean operations, external
functions and literal values.

The RHS of a rule, $RHS$, contains linear ($L$) and persistent ($P$)
\emph{atomic propositions} which are uninstantiated facts. The RHS can also have
\emph{exists expressions} ($EE$), \emph{comprehensions} ($CE$) and
\emph{aggregates} ($AE$). All those expressions may use all the variables
instantiated in the rule's LHS and are explained in detail in
Section~\ref{section:language:expressions}.

\subsubsection{Graph visit using the abstract syntax}\label{visit:ast}

Consider the two rules in the graph visit program shown in
Fig.~\ref{code:language:visit}:

\nopagebreak

\begin{Verbatim}[fontsize=\codesize]
visit(A), unvisited(A) -o visited(A), {B | !edge(A, B) -o visit(B)}.

visit(A), visited(A) -o visited(A).
\end{Verbatim}

To translate the rules to the abstract syntax, we have to de-sugar the code and
introduce the variable \code{A}, that is not explicitly quantified, as follows:

\nopagebreak

\begin{align}
\forall_A. \mathtt{visit}(A), \; \mathtt{unvisited}(A) \lolli & \;
\mathtt{visited}(A), \; \comprehension{B}{\mathtt{edge}(A, B)}{\mathtt{visit}(B)}\\
\forall_A. \mathtt{visit}(A), \; \mathtt{visited}(A) \lolli & \;
\mathtt{visited}(A)
\end{align}

Finally, initial facts are represented as a rule where the LHS is $\one$:

\nopagebreak

\begin{align}
\one \lolli & \bang \mathtt{edge}(@1, @2) \\
\one \lolli & \bang \mathtt{edge}(@2, @3) \\
\one \lolli & \bang \mathtt{edge}(@1, @4) \\
\one \lolli & \bang \mathtt{edge}(@2, @4) \\
\one \lolli & \mathtt{unvisited}(@1)  \\
\one \lolli & \mathtt{unvisited}(@2) \\
\one \lolli & \mathtt{unvisited}(@3) \\
\one \lolli & \mathtt{unvisited}(@4) \\
\one \lolli & \mathtt{visit}(@1)
\end{align}

\subsection{RHS Expressions}\label{section:language:expressions}

\subsubsection{Selectors}

When a rule's LHS is instantiated using facts from the database, facts are
picked non-deterministically. While our system uses an implementation dependent
order for efficiency reasons, sometimes it is important to sort facts by one of
the arguments. The abstract syntax for this construct is
$\selector{S}{y}{LHS}{RHS}$, where $S$ is the selection operation and $y$ is the
variable in $LHS$ that represents the value to be selected according to $S$. An
example using concrete syntax is as follows:

\begin{Verbatim}[fontsize=\codesize]
[min => W | !edge(A, B), weight(A, B, W)] -o picked(A, B, W).
\end{Verbatim}

In this case, we order the \code{weight} facts by \code{W} in ascending order
and then try to match them. Other operations available are \code{max} and
\code{random} (to force no pre-defined order at the implementation level).

\subsubsection{Exists Expression}

Exists constructs ($EE$) are based on the linear logic construct of the same name
and are used to create fresh node addresses. We can use the new address to
instantiate new facts for the new node. As an example, consider the implementation of the
insertion operation for the key/value dictionary described in
Fig.~\ref{code:language:btree_replace}:

\begin{Verbatim}[fontsize=\codesize]
insert(A, IKey, IValue),
value(A, Key, Value),
IKey < Key
   -o value(A, Key, Value),
      exists B. (value(B, IKey, IValue), !left(A, B)).
\end{Verbatim}

The exists construct is used to create the left node of node \code{A} that
contains \code{value(B, IKey, IValue)} (the newly inserted key/value pair) and
the persistent fact \code{!left(A, B)} that connects \code{A} to \code{B}.

\subsubsection{Comprehensions}

Sometimes we need to consume a linear fact and then immediately generate several
facts depending on the contents of the database. To solve this particular need,
we created the concept of comprehensions, which are sub-rules that are applied
with all possible combinations of facts from the database. In a comprehension
$\comprehension{\widehat{x}}{SLHS}{SRHS}$, $\widehat{x}$ is a list of variables
in the scope of $SLHS$ and $SRHS$, $SLHS$ is the comprehension's left-hand side
and $SRHS$ is the right-hand side. $SLHS$ is used to generate all possible
combinations for $SRHS$, according to the facts in the database. We have already
seen an example of comprehensions in the visit program
(Fig.~\ref{code:language:visit} line~\ref{line:language:visit_comprehension}):

\begin{Verbatim}[fontsize=\codesize,commandchars=\*\#\&]
visit(A), unvisited(A) -o visited(A), *textbf#{B | !edge(A, B) -o visit(B)}&.
\end{Verbatim}

We match \code{!edge(A, B)} using all the combinations available in the database
and for each combination we derive \code{visit(B)}.

\subsubsection{Aggregates}

Another useful feature in logic programs is the ability to reduce several facts
into a single fact. LM features aggregates ($AE$), a special kind of sub-rule
that works somewhat like comprehensions. In the abstract syntax
$\aggregate{A}{y}{\widehat{x}}{SLHS}{SRHS_1}{SRHS_2}$, $A$ is the aggregate
operation, $\widehat{x}$ is the list of variables introduced in $SLHS$, $SRHS_1$
and $SRHS_2$ and $y$ is the variable in $SLHS$ that represents the values to be
aggregated using $A$. Like comprehensions, we use $\widehat{x}$ to try all the
combinations of $SLHS$, but, in addition to deriving $SRHS_1$ for each
combination, we aggregate the values represented by $y$ into a new $y$ variable
that is used to derive $SRHS_2$.

To better understand aggregates, let's consider the following rule from the
PageRank program presented in Section~\ref{section:language:pagerank}:

\begin{Verbatim}[fontsize=\codesize]
update(A),
!numInbound(A, T)
   -o [sum => V; B, W, Val, Iter | neighbor-pagerank(A, B, Val, Iter), V =
         Val/float(T) -o neighbor-pagerank(A, B, Val, Iter) -> sum-ranks(A, V)].
\end{Verbatim}

The rule aggregates the PageRank values \code{Val} by iterating over
\code{neighbor-pagerank(A, B, Val, Iter)} (the $SLHS$) and then re-deriving the
fact present in $SRHS_1$ using \code{neighbor-pagerank(A, B, Val, Iter)}. Once all
values are inspected, the atomic proposition \code{sum-ranks(A, V)} present in
$SRHS_2$ is derived once with \code{V} that represents the sum of all the
neighbor values. LM provides several aggregate operations, including the
\code{min} (minimum value), \code{max} (maximum value), \code{sum} (add all
numbers), \code{count} (count combinations) and \code{collect} (collect items
into a list).

\section{Types and Locality}

Each fact is an association between a \emph{predicate} and a tuple of values. A
predicate is a pair with a name and a tuple of types (the argument types). LM
rules are type-checked using the predicate declarations in the header of the
program. LM has a simple type system that includes the following simples types:
\emph{node}, \emph{int}, \emph{float}, \emph{string}, \emph{bool}. The following
structured types are also supported: \emph{list} $X$, for lists of type $X$;
\emph{struct} $X_1, \ldots, X_n$, for composite values made of $n$ elements; and
\emph{array} $X$, for arrays of type $X$.

LM allows definition of new type names from simpler types using the declaration
\code{type simple-type new-type} in the header of the program. The type
\code{new-type} can then be used as any other type. Note that LM uses
\emph{structural equivalence} to check if two types are the same, therefore
\code{simple-type} and \code{new-type} are type equivalent.

Type checking LM programs is straightforward due to its simple type system and
mandatory predicate declarations. For each rule, the variables found in the LHS
are mapped to types based on their use on atomic proposition arguments. Some
constraints of the form \code{X = expression} that force an equality between
\code{X} and \code{expression} may actually represent an assignment of
\code{expression} to \code{X} since \code{X} may not be used in any proposition
argument. In this case, all the variables in \code{expression} must be typed or
else \code{X} becomes an \emph{undefined variable}. Variables in the rule's RHS
must be defined in the LHS, because otherwise derived facts would not be
\emph{ground}, that is, some arguments would be undefined or uncomputable.  For
comprehensions and aggregates, type checking is identical, however, the LHS of
each construct must document the variables in scope using the $\hat{x}$
argument. If a variable is introduced in the LHS that is not in $\hat{x}$, type
checking will fail.

Another important component of type checking is \emph{locality checking}. The
first argument of each atomic proposition in the LHS must use the same variable
in order to enforce locality and allow concurrency. This \emph{home variable} is
always typed as a \emph{node} and represents a node in the program's graph. In
the rule's RHS, other home variables are allowed, as long as they are defined
variables. For comprehensions and aggregates, the LHS must use the same home
argument as the rule's LHS.

\section{Operational Semantics}

As said before, the first argument of every predicate must be typed as a
\emph{node}.  For distribution purposes, the LHS of all rules can only use facts
from the same node in order to make concurrency possible. However, the facts in
the rule's RHS may refer to other nodes, as long as those nodes are instantiated
in the LHS. We drew some inspiration from the Linda system~\cite{linda}
mentioned early on, where the tuple space contains the data and is used by the
processors to communicate and perform computation. This differs from imperative
languages, since in those languages data and computation are two separate
entities.

The execution is performed at the node level and happens non-deterministically
(i.e., any node can be picked to run). This means that the programmer cannot
expect that facts coming from different nodes will be considered as a whole or
partially since the process is non-deterministic. The operational semantics
promises that rule derivations are performed atomically, therefore if a rule
sends many facts to a node then the target node will receive them all at once.
Under these restrictions, computation can then be parallelized by processing
many nodes concurrently.

Each rule in LM has a defined priority that is inferred from its position in the
source file.  Rules at the beginning of the file have higher priority. At the
node level, we consider all the new facts that have not been considered before
to create a priority queue of \emph{candidate rules}. The queue of candidate
rules is then applied (by priority) and updated as new facts are derived or
consumed. As an example, consider the following three rules:

\begin{Verbatim}[fontsize=\codesize]
f(A), g(A) -o f(A).

h(A) -o g(A).

g(A) -o 1.
\end{Verbatim}

If the database contains the facts \code{h(@1)} and \code{f(@1)}, then the
second rule is applied, deriving \code{g(@1)} and retracting \code{h(@1)}. Next,
the first and third rules are candidate rules, but since the first rule has
higher priority, it is applied immediately, resulting in a database with a
single fact \code{f(@1)}.  Section~\ref{sec:implementation:rule_engine} gives
details in how our implementation manages the set of candidate rules.

