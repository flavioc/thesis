Previously, we presented the LM syntax and usage through the presentation of
three program examples. We now delve more deeply into LM by presenting the
underlying abstract syntax of the language in Table~\ref{tbl:language:ast}. A LM
program $Prog$ consists of a list of derivation rules $\Sigma$ and a database
$D$. A database fact $l(\hat{t})$ is an association between a predicate $l$ and
a list of literals $\hat{t}$. Literals $t$ can be either a number
$\m{number}(N)$, a node $\m{node}(N)$, a list $\m{list}(\hat{t})$, among other
literals such as strings, arrays, booleans, etc.

Each derivation rule $R$ can be written as $LHS \lolli RHS$ with the meaning
described in Section~\ref{section:language:message}. Rules without an LHS are
called \emph{initial facts}. All the variables in the rule's scope must be
introduced explicitly in the abstract syntax using the $\forall_x. R$
production. However, when the programmer writes LM programs, those variables are
introduced implicitly. A rule can also use a \emph{selector} of the form
$\selector{S}{y}{LHS}{RHS}$ which allows the programmer to force a specific
ordering during rule derivation. Selectors are described in more detail in
Section~\ref{section:language:selector}.

\newcommand{\sop}[0]{\Vert}

\begin{table}[h]
\centering
\begin{tabular}{ l l c l }
  Program & $Prog$ & $::=$ & $\Sigma, D$ \\
  List Of Rules & $\Sigma$ & $::=$ & $\cdot \; \sop \; \Sigma, R$\\
  Database & $D$ & $::=$ & $\Gamma; \Delta$ \\
  Known Linear Facts & $\Delta$ & $::=$ & $\cdot \; \sop \; \Delta, l(\hat{t})$ \\
  Known Persistent Facts & $\Gamma$ & $::=$ & $\cdot \; \sop \; \Gamma, \bang p(\hat{t})$ \\

  Literal List & $\hat{t}$ & $::=$ & $\cdot \; \sop \; t, \hat{t}$ \\
  Literal & $t$ & $::=$ & $\m{number}(N) \; \sop \; \m{node}(N) \; \sop \; \m{list}(\hat{t}) \; \sop \ldots$ \\
  Rule & $R$ & $::=$ & $LHS \lolli RHS \; \sop \; \forall_{x}. R \; \sop \;
  \selector{S}{y}{LHS}{RHS}$ \\
  LHS Expression & $LHS$ & $::=$ & $L \; \sop \; P \; \sop \; C \; \sop \; LHS,
  LHS \; \sop \; \exists_{x}. LHS \; \sop \; \one$\\
  Selector Operation & $S$ & $::=$ & $\mathtt{asc} \; \sop \; \mathtt{desc} \; \sop \; \mathtt{random}$\\
  RHS Expression & $RHS$ & $::=$ & $L \; \sop \; P \; \sop \; C \; \sop \; RHS, RHS \; \sop
  \; EE \; \sop \; CE \; \sop \; AE \; \sop \; \one$\\
  
  Linear Atomic Proposition & $L$ & $::=$ & $l(\hat{x})$\\
  Persistent Atomic Prop. & $P$ & $::=$ & $\bang p(\hat{x})$\\
  Term List & $\hat{x}$ & $::=$ & $\cdot \; \sop \; x, \hat{x} \; \sop \; t, \hat{x}$ \\
  Constraint & $C$ & $::=$ & $e \; O \; e$ \\
  Expression & $e$ & $::=$ & $x \; \sop \; t \; \sop \; \m{fun}(\hat{e}) \; \sop
  e \; M \; e \; \sop \; e \; O \; e$ \\
  Expression List & $\hat{e}$ & $::=$ & $\cdot \; \sop \; e, \hat{e}$ \\
  Math Operation & $M$ & $::=$ & $+ \; \sop \; \times \; \sop \; / \; \sop \; - \; \sop \; \%$ \\
  Boolean Operation & $O$ & $::=$ & $= \; \sop \; <> \; \sop \; > \; \sop \;
  \geq \; \sop \; < \; \sop \; \leq $ \\

  
  Exists Expression & $EE$ & $::=$ & $\existsc{\widehat{x}}{SRHS}$ \\
  Comprehension & $CE$ & $::=$ & $\comprehension{\widehat{x}}{SLHS}{SRHS}$ \\

  Aggregate & $AE$ & $::=$ & $\aggregate{A}{y}{\widehat{x}}{SLHS}{SRHS_1}{SRHS_2}$ \\
  Aggregate Operation & $A$ & $::=$ & $\mathtt{min} \; \sop \; \mathtt{max} \; \sop \;
\mathtt{sum} \; \sop \; \mathtt{count} \; \sop \; \mathtt{collect}$ \\
  
  Sub-LHS & $SLHS$ & $::=$ & $L \; \sop \; P \; \sop \; SLHS, SLHS \; \sop \; \exists_{x}. SLHS$\\
  Sub-RHS & $SRHS$ & $::=$ & $L \; \sop \; P \; \sop \; SRHS, SRHS \; \sop \; \one$\\
  
\end{tabular}
\mycap{Core abstract syntax of LM.}\label{tbl:language:ast}
\end{table}

The $LHS$ of a rule may contain linear ($L$) and persistent ($P$) \emph{atomic
propositions} and constraints ($C$). Atomic propositions are template facts that
instantiate variables from facts in the database (example in
line~\ref{line:language:visit_second1} of Fig.~\ref{code:language:visit}).
Variables can be used again in the LHS for matching and also in the RHS when
instantiating facts.  Constraints $C$ are boolean expressions that must be true
in order for the rule to be derived. Each constraint starts with a boolean
operation $e \; O \; e$, where each expression $e$ may be a literal, a variable,
a function call $\m{fun}(\hat{e})$ or a mathematical operation $e \; M \; e$.

The $RHS$ of a rule contains linear ($L$) and persistent ($P$) atomic
propositions which are uninstantiated facts. The RHS can also have \emph{exists
expressions} ($EE$), \emph{comprehensions} ($CE$) and \emph{aggregates} ($AE$).
All those expressions may use all the variables instantiated in the rule's LHS
and are explained in Section~\ref{section:language:expressions}.
To introduce variables in the scope of the RHS, it is possible to use the
$\exists_x. LHS$ production, which can be used for sub-computations for
instantiating the atomic propositions of the RHS. This production is heavily
used by the compiler to move variables defined in the rule's LHS to the RHS
which are only used in the RHS, however it is still possible for the programmer
to define RHS's variables explicitly using an equality constraint of the form $x
= e$ (represented by $C$ in the syntax).

Consider again the two rules in the graph visit program shown in
Fig.~\ref{code:language:visit}:

\nopagebreak

\begin{Code}
visit(A),
unvisited(A)
   -o visited(A),
      {B | !edge(A, B) -o visit(B)}.

visit(A),
visited(A)
   -o visited(A).
\end{Code}

To translate the rules to the abstract syntax, we have to de-sugar the code and
introduce the variable \code{A}, that is not explicitly quantified, as follows:

\nopagebreak

\begin{align}
\forall_A. \mathtt{visit}(A), \; \mathtt{unvisited}(A) \lolli & \;
\mathtt{visited}(A), \; \comprehension{B}{\bang\mathtt{edge}(A, B)}{\mathtt{visit}(B)}\\
\forall_A. \mathtt{visit}(A), \; \mathtt{visited}(A) \lolli & \;
\mathtt{visited}(A)
\end{align}

For the initial facts, they are translated as rules where the LHS is $\one$:

\nopagebreak

\begin{align}
\one \lolli \; & \bang \mathtt{edge}(@1, @2) \\
\one \lolli \; & \bang \mathtt{edge}(@2, @3) \\
\one \lolli \; & \bang \mathtt{edge}(@1, @4) \\
\one \lolli \; & \bang \mathtt{edge}(@2, @4) \\
\one \lolli \; & \mathtt{unvisited}(@1)  \\
\one \lolli \; & \mathtt{unvisited}(@2) \\
\one \lolli \; & \mathtt{unvisited}(@3) \\
\one \lolli \; & \mathtt{unvisited}(@4) \\
\one \lolli \; & \mathtt{visit}(@1)
\end{align}

\subsection{Selectors}\label{section:language:selector}

When a rule's LHS is instantiated using facts from the database, facts are
picked non-deterministically. While our system uses an implementation dependent
order for efficiency reasons, sometimes it is important to sort facts by one of
the arguments. The abstract syntax for this construct is
$\selector{S}{y}{LHS}{RHS}$, where $S$ is the selector operation and $y$ is the
variable in $LHS$ that represents the value to be sorted according to $S$. An
example using concrete syntax is as follows:

\begin{Code}[commandchars=\*\#\&]
*textbf#[asc => W | !edge(A, B, W), select(A)]& -o best-neighbor(A, B, W).
\end{Code}

In this case, we sort the \code{edge} facts by \code{W} in ascending order
and then try to match them. Other operations available are \code{desc} and
\code{random} (to force no pre-defined order at the implementation level).

\subsection{Exists Expressions}\label{section:language:expressions}

Exists constructs ($EE$) are based on the linear logic construct of the same
name and are used to create fresh node addresses. We can use the new node address to
instantiate new facts. As an example, consider extending the
key/value dictionary example described in Fig.~\ref{code:language:btree_replace}
with an insertion operation for a node that has no left branch:

\begin{Code}[commandchars=\*\#\&]
insert(A, IKey, IValue),
value(A, Key, Value),
no-left-branch(A),
IKey < Key
   -o value(A, Key, Value),
      *textbf#exists B. (value(B, IKey, IValue), !left(A, B))&.
\end{Code}

The \code{exists} construct creates a new node \code{B} containing the linear fact
\code{value(B, IKey, IValue)} (the newly inserted key/value pair) and the
persistent fact \code{!left(A, B)} that connects \code{A} to \code{B} is also
added to node \code{A}.

\subsection{Comprehensions}

Sometimes, when consuming a linear fact, we might want to generate several new
facts depending on the contents of the database. To solve this particular need,
we use comprehensions, which are sub-rules that are applied with all possible
combinations of facts from the database. In a comprehension
$\comprehension{\widehat{x}}{SLHS}{SRHS}$, $\widehat{x}$ is a list of variables
in the scope of $SLHS$ and $SRHS$ being $SLHS$ the comprehension's left-hand
side and $SRHS$ the comprehension's right-hand side. $SLHS$ is used to generate
all possible combinations for $SRHS$, according to the list of variables
$\hat{x}$ and to the facts in the database. We have already seen an example of a
comprehension in the graph visit program (Fig.~\ref{code:language:visit}
line~\ref{line:language:visit_comprehension}):

\begin{Code}[commandchars=\*\#\&]
visit(A),
unvisited(A)
   -o visited(A),
      *textbf#{B | !edge(A, B) -o visit(B)}&.
\end{Code}

In this example, the comprehension matches \code{!edge(A, B)} using all the
combinations available in the database for node \code{B} and for each
combination it derives \code{visit(B)}.

\subsection{Aggregates}

Another useful feature is the ability to reduce several facts
into a single fact. LM features aggregates ($AE$), a special kind of sub-rule
that works somewhat like comprehensions. In the abstract syntax
$\aggregate{A}{y}{\widehat{x}}{SLHS}{SRHS_1}{SRHS_2}$, $A$ is the aggregate
operation, $\widehat{x}$ is the list of variables introduced in $SLHS$, $SRHS_1$
and $SRHS_2$ and $y$ is the variable in $SLHS$ that represents the values to be
aggregated using $A$. Like comprehensions, we use $\widehat{x}$ to try all the
combinations of $SLHS$, but, in addition to deriving $SRHS_1$ for each
combination, we aggregate the values represented by $y$ into a new $y$ variable
that is used to derive $SRHS_2$.

To understand how aggregates work, let's consider the following rule:

\begin{Code}[commandchars=\*\#\&]
count-neighbors(A) -o *textbf#[count => T; B | !edge(A, B) -o 1 -> num-neighbors(A, T)]&.
\end{Code}

The rule uses a \code{count-neighbors} proposition to iterate over all
\code{!edge} facts (the $SLHS$) of node \code{A}. Since the $SRHS_1$ of the
aggregate is \code{1}, nothing is derived for each \code{!edge}. Since we use a
\code{count} aggregate, for each \code{!edge} fact, the variable \code{T} is
incremented by one and the total result is used to derive a single
\code{num-neighbors(A, T)} fact (the $SRHS_2$).

To further understand aggregates, let's consider a rule from the PageRank
program to be presented in Section~\ref{section:language:pagerank}:

\begin{Code}[commandchars=\*\#\&]
update(A),
!numInbound(A, T)
   -o *textbf#[sum => V; B, Val, Iter | neighbor-pagerank(A, B, Val, Iter), V =&
         *textbf#Val/float(T) -o neighbor-pagerank(A, B, Val, Iter) -> sum-ranks(A, V)]&.
\end{Code}

The rule aggregates the values \code{V} by iterating over
\code{neighbor-pagerank(A, B, Val, Iter)} (the $SLHS$) and by re-deriving the
fact \code{neighbor-pagerank(A, B, Val, Iter)} (the $SHRS_1$). Once all
values are inspected, the atomic proposition \code{sum-ranks(A, V)} present in
$SRHS_2$ is derived once with \code{V} representing the sum of all the
neighbor values \code{Val/float(T)}. LM provides several aggregate operations, including the
\code{min} (minimum value), \code{max} (maximum value), \code{sum} (add all
numbers), \code{count} (count combinations) and \code{collect} (collect items
into a list).

