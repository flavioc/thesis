In this section, we present solutions to well-known problems. We start with
straightforward graph-based problems such as bipartitness checking and two
versions of the PageRank program. Next, we present the LM version of the
Quick-Sort algorithm, which from a first impression may not fit well under the
programming paradigm offered by LM. Informal correctness and termination proofs
are also included to further show that such important properties are relatively
easy to prove for programs written in LM.

\subsection{Bipartiteness Checking}

The problem of checking if a graph is bipartite can be seen as a 2-color graph
coloring problem.  The code for this algorithm is shown in
Fig.~\ref{language:code:bichecking}. All nodes in the graph start as
\texttt{uncolored}, because they do not have a color yet. The axiom
\texttt{visit(@1, 1)} is instantiated at node \texttt{@1}
(line~\ref{line:language:bc_axiom}) in order to color it with color 1.

If a node is \texttt{uncolored} and needs to be marked with a color \texttt{P}
then the rule in
lines~\ref{line:language:bc_first1}-\ref{line:language:bc_first2} is applied. We
consume the \texttt{uncolored} fact and derive a \texttt{colored(A, P)} to
effectively color the node with \texttt{P}. We also derive \texttt{visit(B,
next(P))} in neighbor nodes to color them with the other color. 

The coloring can fail if a node is already colored with a color \texttt{P} and
needs to be colored with a different color (line~\ref{line:language:bc_third})
or if it has already failed (line~\ref{line:language:bc_fourth}).

\begin{figure}[h!]
\begin{Verbatim}[numbers=left,fontsize=\codesize,commandchars=\*\[\]]
type route edge(node, node).
type linear visit(node, int).
type linear uncolored(node).
type linear colored(node, int).
type linear fail(node).

fun next(int X) : int = if X <> 1 then 1 else 2 end.

visit(@1, 1).*label[line:language:bc_axiom]

visit(A, P), uncolored(A)*label[line:language:bc_first1]
   -o {B | !edge(A, B) | visit(B, next(P))},
      colored(A, P).*label[line:language:bc_first2]

visit(A, P), colored(A, P) -o colored(A, P).*label[line:language:bc_second]
visit(A, P1), colored(A, P2), P1 <> P2 -o fail(A).*label[line:language:bc_third]
visit(A, P), fail(A) -o fail(A).*label[line:language:bc_fourth]
\end{Verbatim}
  \caption{Bipartiteness Checking program.}
  \label{language:code:bichecking}
\end{figure}

\subsubsection{Proof Of Correctness}

In order to show that the code in Fig.~\ref{language:code:bichecking} works as
intended, we first setup some invariants that hold throughout the execution of
the program. Assume that the set of nodes in the graph is represented as $N$.

\begin{invariant}[Node state]
Set of nodes $N$ is partitioned into 4 different states that represent the 4
possible states that a node can be in, namely:

\begin{itemize}
   \item $U$ (\texttt{uncolored} nodes)
   \item $F$ (\texttt{fail} nodes)
   \item $C_{true}$ (\texttt{colored(A, 1)} nodes)
   \item $C_{false}$ (\texttt{colored(A, 2)} nodes)
\end{itemize}
\end{invariant}
\begin{proof}
Initially, all nodes start in set $U$. All the 4 rules of the programs either
keep the node in the same set or exchange the node with another set.
\end{proof}

A bipartite graph is one where in every edge $a \leftrightarrow b$, there is a
valid assignment that makes $a$ member of set $C_{true}$ or $C_{false}$ and node
$b$ member of either $C_{false}$ or $C_{true}$ respectively.

\begin{lemma}[Bipartiteness
   Convergence]\label{language:lemma:bipartite_convergence}
   We now reason from the application of the program rules. After each
   application of an inference rule, one of the following will happen:

   \begin{itemize}
      \item Set $U$ will decrease and set $C_{true}$ or $C_{false}$ will
         increase, with a potential increase in the number of \texttt{visit}
         facts.
      \item Set $C_{true}$ or $C_{false}$ will stay the same, while the number
         of \texttt{visit} facts will be reduced.

      \item Set $C_{true}$ or $C_{false}$ will decrease and set $F$ will
         increase, while the number of \texttt{visit} facts will be reduced.

      \item Set $F$ will stay the same, while the number of \texttt{visit} facts
         decreases.
   \end{itemize}

\end{lemma}
\begin{proof}
Directly from the rules.
\end{proof}

From this invariant, it can be inferred that set $U$ never increases in size
and in a node transition from \texttt{uncolored} to \texttt{colored}, the
database may increase in size. For every other rule application, the database of
facts always decreases. This also means that the program will eventually
terminate, since it is limited by the number of \texttt{visit} facts that can be
generated.

\begin{theorem}[Bipartiteness Correctness]
If the graph is connected and bipartite then the nodes will be partitioned into
sets $C_{true}$ and $C_{false}$, while sets $F$ and $U$ are empty.
\end{theorem}
\begin{proof}
   By induction, we prove that uncolored nodes become part of either $C_{true}$
   and $C_{false}$ and, if there is an edge between nodes in the two sets then
   they have different colors.

   In the base case, we start with empty sets but node \texttt{@1} is made
   member of $C_{true}$. Rule 1 sends \texttt{visit} facts to the neighbors of
   \texttt{@1}, forcing them to be members of $C_{false}$.

   In the inductive case, we have sets $C'_{true}$ and $C'_{false}$ with some
   nodes already colored. From Lemma~\ref{language:lemma:bipartite_convergence},
   we know that $U$ always decreases. Since the graph is bipartite, events 3 and
   4 never happen since there is a possible partitioning of nodes. With event 1,
   we have set $C_{true} = C'_{true}, n$, (or $C_{false}$) where $n$ is the
   node and with event 2, the sets remain the same. Since the graph is
   connected, every node will be colored, therefore event 1 will happen for
   every node of the graph.
\end{proof}

\subsection{PageRank}

PageRank~\cite{Page:2001:MNR} is a well known graph algorithm that is used to
compute the relative relevance of web pages.  The code for a synchronous version
of the algorithm is shown in Fig.~\ref{language:code:pagerank}. As the name
indicates, the pagerank is computed for a certain number of iterations. The
initial pagerank is the same for every page and is initialized in the first rule
(lines
\ref{line:language:spagerank_first1}-\ref{line:language:spagerank_first2}) along
with an accumulator.

The second rule of the program
(lines~\ref{line:language:spagerank_second1}-\ref{line:language:spagerank_second2})
propagates a newly computed pagerank value to all neighbors. The fact
\texttt{neighbor-pagerank} informs the neighbor node about the pagerank value of
node \texttt{A} for iteration \texttt{Iter + 1}. For every iteration, each node
will accumulate the all the \texttt{neighbor-pagerank} facts into the
\texttt{accumulator} fact (lines
\ref{line:language:spagerank_fourth1}-\ref{line:language:spagerank_fourth2}).
When all inbound neighbor pagerank values are accumulated, the third rule
(lines~\ref{line:language:spagerank_third1}-\ref{line:language:spagerank_third2})
is derived and a pagerank value is generated for iteration \texttt{Iter}.

\begin{figure}[h!]
\begin{Verbatim}[numbers=left,fontsize=\codesize,commandchars=\*\[\]]
type outbound(node, node, float).
type linear pagerank(node, float, int).
type numInbound(node, int).
type linear accumulator(node, float Acc, int Left, int Iteration).
type linear neighbor-pagerank(node, node Neighbor, float Rank, int Iteration).
type linear start(node).

const damping = 0.85. // probability of user following a link in the current page.
const iterations = str2int(@arg1). // iterations to compute.
const pages = @world. // number of pages in the graph.

start(A).

start(A), !numInbound(A, T)*label[line:language:spagerank_first1]
   -o accumulator(A, 0.0, T, 1), pagerank(A, 1.0 / float(pages), 0).*label[line:language:spagerank_first2]

pagerank(A, V, Iter), // propagate new pagerank value*label[line:language:spagerank_second1]
Iter < iterations
   -o {B, W | !outbound(A, B, W) | neighbor-pagerank(B, A, V * W, Iter + 1)}.*label[line:language:spagerank_second2]

accumulator(A, Acc, 0, Iter), // new pagerank*label[line:language:spagerank_third1]
!numInbound(A, T),
V = damping + (1.0 - damping) * Acc,
Iter <= iterations
   -o pagerank(A, V, Iter), accumulator(A, 0.0, T, Iter + 1).*label[line:language:spagerank_third2]
	
neighbor-pagerank(A, B, V, Iter), accumulator(A, Acc, T, Iter)*label[line:language:spagerank_fourth1]
   -o accumulator(A, Acc + V, T - 1, Iter).*label[line:language:spagerank_fourth2]
\end{Verbatim}
\caption{Synchronous PageRank program.}
\label{language:code:pagerank}
\end{figure}

\subsubsection{Asynchronous PageRank}

We also have an asynchronous version of the algorithm that trades correctness
with convergence speed since it does not synchronize between iterations.
Figure~\ref{language:code:async_pagerank} shows the LM code for this particular
version, where two major differences can be observed: (1) there is a linear fact
\texttt{neighbor-pagerank} containing the most up-to-date pagerank value of a
neighbor node; (2) a new \texttt{update} fact that forces the node to re-compute
its pagerank by processing the currently available \texttt{neighbor-pagerank}
facts. Rules in
lines~\ref{line:language:apagerank_update1}-\ref{line:language:apagerank_update2}
update the \texttt{neighbor-pagerank} values, while rule in
lines~\ref{line:language:apagerank_new1}-\ref{line:language:apagerank_new2}
asynchronously update the current pagerank value. This last rule derives
multiple \texttt{new-neighbor-rank} that is used to inform the neighbor about
the new pagerank value.

\begin{figure}[h!]
\begin{Verbatim}[numbers=left,fontsize=\codesize,commandchars=\*\#\&]
type outbound(node, node, float).
type linear pagerank(node, float, int).
type numInbound(node, int).
type linear neighbor-pagerank(node, node Neighbor, float Rank, int Iteration).
type linear new-neighbor-rank(node, node Neighbor, float Rank, int Iteration).
type linear update(A).
type linear sum-ranks(node, float).

pagerank(A, 1.0 / float(pages), 0).
update(A).
neighbor-pagerank(A, B, 1.0 / float(pages), 0). // pagerank of B is ...

// save incoming pagerank value.*label#line:language:apagerank_update1&
new-neighbor-rank(A, B, New, Iteration),
neighbor-pagerank(A, B, Old, OldIteration),
Iteration > OldIteration
   -o neighbor-pagerank(A, B, New, Iteration).
new-neighbor-rank(A, B, New, Iteration),
neighbor-pagerank(A, B, Old, OldIteration),
Iteration <= OldIteration
   -o neighbor-pagerank(A, B, Old, OldIteration).*label#line:language:apagerank_update2&

sum-ranks(A, Acc),
NewRank = damping/float(pages) + (1.0 - damping) * Acc,
pagerank(A, OldRank, Iteration)
      -o pagerank(A, NewRank, Iteration + 1),
         {B, W, Delta, Iter | !outbound(A, B, W), Delta = fabs(NewRank -
               OldRank) * W | new-neighbor-rank(B, A, NewRank, Iteration + 1),
               if Delta > bound then update(B) end}.

update(A), update(A) -o update(A).

update(A),*label#line:language:apagerank_new1&
!numInbound(A, T)
   -o [sum => V | B, W, Val, Iter | neighbor-pagerank(A, B, Val, Iter),
         V = Val/float(T) | neighbor-pagerank(A, B, Val, Iter) | sum-ranks(A, V)].*label#line:language:apagerank_new2&
\end{Verbatim}
\caption{Asynchronous PageRank program.}
\label{language:code:async_pagerank}
\end{figure}

\subsubsection{Proof Of Correctness}

To build the proof of correctness, we must again prove several program
invariants. This will help us prove that this partifcular program is similar to
a computation on a nonnegative matrix of of unit spectral radius, which has been
proven that it converges~\cite{DBLP:journals/corr/abs-cs-0606047,
Lubachevsky:1986:CAA:4904.4801}.

\begin{invariant}[Page Invariant]
Each page/node has a single \texttt{pagerank(A, Value, Iteration)} and:
\begin{itemize}
   \item For each outbound link, a single \texttt{\bang outbound(A, B, W)}.
   \item For each inbound link, a single \texttt{neighbor-pagerank(A, B, V, Iter)}.
   \item For each \texttt{\bang outbound(A, B, W)}, a \texttt{neighbor-pagerank(A,
      B, V, Iter}.
\end{itemize}
\end{invariant}

\begin{proof}

All initial facts validate the 3 conditions of the variant. Note that the third
condition is also validated by the initial facts, although not all facts are shown in
the code.

In relation to rule application:

\begin{itemize}
   \item Rule 1: inbound link re-derived.
   \item Rule 2: inbound link re-derived.
   \item Rule 3: \texttt{pagerank/2} re-derived.
   \item Rule 4: Nothing happens.
   \item Rule 5: inbound links re-derived in the comprehension.
\end{itemize}
\end{proof}

\begin{lemma}[Neighbor rank lemma]
Given a fact \texttt{neighbor-pagerank(A, B, V, Iter)} and a set of facts
\texttt{new-neighbor-rank(A, B, New, Iter2)}, we end up with a single
\texttt{neighbor-pagerank(A, B, V', Iter')}, where \texttt{Iter} is the greater of
\texttt{Iter} or all of \texttt{Iter2'}.
\end{lemma}
\begin{proof}
By induction on the number of \texttt{new-neighbor-rank} facts.

Base case: \texttt{neighbor-pagerank} remains.

Inductive case: given one \texttt{new-neighbor-rank} fact:

\begin{itemize}
   \item Rule 1: the new iteration is older and thus \texttt{neighbor-pagerank}
   is replaced. By applying induction, we know that we will select either the
   new best iteration or a better iteration from the remaining set of
   \texttt{new-neighbor-rank} facts.
   \item Rule 2: the new iteration is not older and we keep the old
   \texttt{neighbor-pagerank} fact. By induction, we select the best from either
   the current iteration or some other (from the set).
\end{itemize}
\end{proof}

\begin{lemma}[Update lemma]
Given at least 1 \texttt{update/1} fact, rule 7 will run.
\end{lemma}
\begin{proof}
By induction on the number of \texttt{update} facts.

Base case: rule 5 will run.

Inductive case: rule 4 will run first because it has a higher priority, reducing
the number of \texttt{update} facts by one. By induction, we know that by
using the remaining \texttt{update} facts, rule 7 will run.
\end{proof}

\begin{lemma}[Pagerank update lemma]
(1) Given at least one \texttt{update} fact, the \texttt{pagerank(A, $V_{I}$,
I)} fact will be updated to become \texttt{pagerank(A, $V_{I + 1}$, I +
1)}, where \texttt{$V_{I + 1} = damping / P + (1.0 - damping)\sum_{B,
I} (W_{B} \times  N_{I,B})$}.

where $W_B = 1.0/T$ ($T$ from \texttt{\bang numInbound(A, $T$)})
and $N_{I,B}$ from \texttt{neighbor-pagerank(A, B, $N_{I, B}$, $I$)}.

(2) For all \texttt{B} outbound nodes (represented using \texttt{\bang outbound(A, B,
W)}, a \texttt{new-neighbor-rank(B, A, $V_{I+1}$, $I + 1$)} is generated.

(3) For all \texttt{B} outbound nodes (represented using \texttt{\bang outbound(A, B,
W)}), a \texttt{update(B)} is generated if 
$fabs(V_{I + 1} - V_{I}) \times W > bound$.
\end{lemma}
\begin{proof}
Using the Update lemma, rule 5 will necessarily run.

It derives \texttt{sum-ranks(A, $\sum_{B, I} (W_B \times N_{I,B})$)} and
fulfills (3).

\texttt{sum-ranks/2} will necessarily fire rule 6,
computing $V_{I+1}$ and updating \texttt{pagerank}. (2) and (3) are fulfilled
through the comprehension of rule 6.
\end{proof}

\begin{invariant}[New neighbor rank equality]
All \texttt{new-neighbor-rank(A, B, V, I)} facts are generated from a corresponding
\texttt{pagerank(B, V, I)} fact, therefore the iteration of any
\texttt{new-neighbor-rank} is at least the same or less than the iteration of
the current pagerank.
\end{invariant}
\begin{proof}
No initial facts to prove.

\begin{itemize}
   \item Rule 3: true, new fact is generated.
   \item Rule 6: the fact is kept.
\end{itemize}
\end{proof}

\begin{invariant}[Neighbor rank equality]
All \texttt{neighbor-pagerank(A, B, V, I)} facts have one corresponding
\texttt{pagerank(B, V, I)} fact and the iteration of the \texttt{neighbor-pagerank}
is the same or less than the current iteration of the corresponding
\texttt{pagerank}.
\end{invariant}
\begin{proof}
By analyzing initial facts and rules.

Axioms: true.

Rule cases:

\begin{itemize}
   \item Rule 1: uses \texttt{new-neighbor-rank} fact (use new neighbor rank
         equality invariant).
   \item Rule 2: same fact is re-derived.
\end{itemize}
\end{proof}

\begin{theorem}[Pagerank convergence]
The program will compute the pagerank of all nodes that is within \texttt{bound} error
of an asynchronous pagerank computation.
\end{theorem}
\begin{proof}

Using the program initial facts, we start with the same pagerank value for all nodes.
The \texttt{\bang outbound(A, B, W)} fact forms a $n \times n$ square matrix (number
of nodes) and is the so-called "Google Matrix".  All the initial pagerank values
can be seen as a vector that adds up to $1$.

The pagerank computation from the "Pagerank update lemma" computes $V_{I + 1} =
damping / P + (1.0 - damping)\sum_{B, I'} (W_{B} \times N_{I',B})$, where $I' <=
I$
(from Neighbor rank equality invariant).

Consider that each node contains a column $G_i$ of the Google matrix. The
pagerank computation can then be represented as: \newline


$V_{I + 1} = G_i fix([N_{I_1, B_1}, ..., N_{I_p, B_p}])$ \hfill (1) \\


Where $p$ is the number of inbound links and $N_{I_j, B_j}$ is the value of
the \texttt{neighbor-pagerank(A, $B_j$, $N_{I_j, B_j}$, $I_j$)}. The $fix()$
function takes the neighbor vector and expands it with zeros corresponding to
nodes that are not inbound links.

From~\cite{DBLP:journals/corr/abs-cs-0606047, Lubachevsky:1986:CAA:4904.4801} we
know that equation (1) will improve (converge) the pagerank value, given that some new
neighbor pagerank values are sent to node $i$ and by the fact that $G_i$ is a
nonnegative matrix of unit spectral radius. Let's use induction by assuming that there
is at least one \texttt{update/1} fact that
schedules a node to improve its pagerank. We want to prove that such fact will
not only improve the node's pagerank but also the pagerank vector.
If the pagerank vector is now close enough (within \texttt{bound}), then the
program will terminate.

\begin{itemize}
   \item Base case: Since we have an \texttt{update} fact as an axiom, rule 7
   will compute a new pagerank (Pagerank update lemma) for all nodes that is
   improved (from equation (1)). From these updates, a new \texttt{update}
   fact is generated that correspond to nodes that have inbound links from the
   source node and need to update their pagerank. These \texttt{update} facts
   may not be generated if the pagerank vector is close enough to its real
   value.

   \item The induction hypothesis tells us that there is at least one node that
   has an \texttt{update} fact. From pagerank update lemma, this
   generates \texttt{new-neighbor-rank} facts if the new value differs
   significantly from the older value. When this happens and using the ``Neighbor
   rank lemma'', the target node will update its \texttt{neighbor-pagerank} fact
   with the newest iteration and then execute a valid pagerank computation that
   brings the pagerank vector close to its solution.

\end{itemize}

\end{proof}

\subsection{Quick-Sort}

The Quick-Sort algorithm is a divide and conquer sorting algorithm that works by splitting
a list of items into two sublists and then recursively sorting the two sublists.
To split the list, we pick a pivot element and put the items that are smaller than the pivot
into the first sublist and items greater than the pivot into the second list.

The Quick-Sort algorithm is interesting because it does not map immediately to
the graph-based model of LM. Our approach considers that the program starts with
a single node where the initial list is located. Then the list is split as usual
and two nodes are created that will recursively sort the sublists.
Interestingly, this creates a tree that will look similar to a call tree in a
functional programming language.

Fig.~\ref{language:code:quicksort} presents the code for the quick-sort
algorithm in LM. For each sublist to sort, we start with a \texttt{down} fact
that must be (eventually) transformed into an \texttt{up} fact, where the
sublist in the \texttt{up} fact is sorted.  In line~\ref{line:language:qs_axiom}
we start with the initial list at node \texttt{@0}. If the list has a small
number of items, then
lines~\ref{line:language:qs_small1}-\ref{line:language:qs_small2} will
immediately sort it, otherwise the rule in line~\ref{line:language:qs_complex} is applied.  \texttt{split}
first splits the list using the pivot \texttt{Pivot} using rules in
lines~\ref{line:language:qs_split1}-\ref{line:language:qs_split2}.
When there is nothing more to split, the rule in
lines~\ref{line:language:qs_exists1}-\ref{line:language:qs_exists2} uses an
exists construct to create nodes \texttt{B} and \texttt{C}. The sublists are
then sent to nodes \texttt{B} and \texttt{C} using \texttt{down} facts.  Note,
however, that \texttt{back} facts are also derived and are going to be used to
send the sorted list back to the parent using the rule in
line~\ref{line:language:qs_back}.

When the sublists are finally sorted, two \texttt{sorted} facts are derived that
must be matched against \texttt{waitpivot} in the rule in
lines~\ref{line:language:qs_sorted1}-\ref{line:language:qs_sorted2}. The sorted
sublists are appended and then an \texttt{up} fact is finally derived
(line~\ref{line:language:qs_up}).

\begin{figure}[h!]
\begin{Verbatim}[numbers=left,fontsize=\codesize,commandchars=\*\{\}]
type route back(node, node).
type linear down(node, list int).
type linear up(node, list int).
type linear sorted(node, node, list int).
type linear split(node, int list int, list int, list int).
type linear waitpivot(node, int, node, node).
type linear reverse(node, list int, list int, list int).
type linear append(node, list int, list int).

down(@0, tosort).*label{line:language:qs_axiom}

down(A, []) -o up(A, []).*label{line:language:qs_small1}
down(A, [X]) -o up(A, [X]).
down(A, [X, Y]), X < Y -o up(A, [X, Y]).
down(A, [X, Y]), X >= Y -o up(A, [Y, X]).*label{line:language:qs_small2}
down(A, [Pivot | Xs]) -o split(A, Pivot, Xs, [], []).*label{line:language:qs_complex}

split(A, Pivot, [], Smaller, Greater) -o*label{line:language:qs_exists1}
   exists B, C. (back(B, A), back(C, A),
                 down(B, Smaller), down(C, Greater), waitpivot(A, Pivot, B, C)).*label{line:language:qs_exists2}

split(A, Pivot, [X | Xs], Smaller, Greater), X <= Pivot*label{line:language:qs_split1}
   -o split(A, Pivot, Xs, [Y | Smaller], Greater).
split(A, Pivot, [X | Xs], Smaller, Greater), X > Pivot
   -o split(A, Pivot, Xs, Smaller, [Y | Greater]).*label{line:language:qs_split2}
   
waitpivot(A, Pivot, NodeSmaller, NodeGreater),*label{line:language:qs_sorted1}
sorted(A, NodeSmaller, Smaller),
sorted(A, NodeGreater, Greater)
   -o reverse(A, Smaller, [], [Pivot | Greater]).*label{line:language:qs_sorted2}

reverse(A, [X | Xs], S, G) -o reverse(A, Xs, [X | S], G).
reverse(A, [], S, G) -o append(A, S, G).

append(A, [X | Xs], L) -o append(A, Xs, [X | L]).
append(A, [], Result) -o up(A, Result).*label{line:language:qs_up}

up(A, L), back(A, B) -o sorted(B, A, L).*label{line:language:qs_back}
\end{Verbatim}
  \caption{Quick-Sort program written in LM.}
  \label{language:code:quicksort}
\end{figure}

The Quick-Sort program shows that it is possible for applications to manipulate
and change the structure of the graph during run time. This is possible with the
use of the exists operator, which allows the programmer to create new nodes
where facts can be derived. In the case of the Quick-Sort, it allows the program
to create a tree of nodes where sorting can take place concurrently.

\subsubsection{Proof Of Correctness}

The proof of correctness for Quick-Sort will follow a different style than what
we have done up to this point. Instead of proving invariants, we prove what
happens to the database given the presence of some logical facts.

\begin{lemma}[Split lemma]

If fact \texttt{split(A, Pivot, L, Small, Great)} exists then it will be
consumed and \texttt{split(A, Pivot, [], Small' ++ Small, Great' ++ Great)} will
be derived, where elements of \texttt{Small'} are \texttt{<=} \texttt{Pivot} and
elements of \texttt{Great'} are \texttt{> Pivot}.

\end{lemma}
\begin{proof}
By induction on the size of \texttt{L}.
\end{proof}

\begin{lemma}[Reverse lemma]

If fact \texttt{reverse(A, L, R, G)} exists then it will be consumed and
\texttt{reverse(A, [], R' ++ R, G)} will be derived, where \texttt{R'} is the
reverse of \texttt{L}.

\end{lemma}
\begin{proof}
By induction on the size of $L$.
\end{proof}

\begin{lemma}[Append lemma]
If fact \texttt{append(A, L, R)} exists then it will be consumed and
\texttt{append(A, [], R' ++ R)} will be derived, where \texttt{R'} is the reverse of \texttt{L}.
\end{lemma}
\begin{proof}
By induction on the size of $L$.
\end{proof}

\begin{theorem}[Sort theorem]
If fact \texttt{down(A, L)} exists then it will be consumed and a \texttt{up(A,
L')} fact will be derived, where \texttt{L'} is the sorted list.
\end{theorem}
\begin{proof}
By induction on the size of \texttt{L}.

The base cases are proven trivially.

In the inductive case we have:
\begin{Verbatim}[fontsize=\codesize]
down(A, [Pivot | Xs]) -o split(A, Pivot, Xs, [], []).
\end{Verbatim}

We necessarily derive \texttt{split(A, Pivot, Xs, [], [])}. Using the split
lemma we get \texttt{split(A, Pivot, Smaller, Greater)}. With this linear fact
we can only use the rule:

\begin{Verbatim}[fontsize=\codesize]
split(A, Pivot, [], Smaller, Greater) -o
   exists B, C. (back(B, A), back(C, A),
                 down(B, Smaller), down(C, Greater), waitpivot(A, Pivot, B, C)).
\end{Verbatim}

We derive \texttt{back(B, A)}, \texttt{back(C, A)}, \texttt{down(B, Smaller)},
\texttt{down(C, Greater)} and \texttt{waitpivot(A, Pivot, B, C)}. We know that
\texttt{Smaller} and \texttt{Greater} are both smaller (in size) than
\texttt{L}, so, if we use the induction hypothesis, we get \texttt{up(B,
Smaller')} and \texttt{up(C, Greater')}.  These last two facts will be applied
using the following rule:

\begin{Verbatim}[fontsize=\codesize]
up(A, L), back(A, B) -o sorted(B, A, L).
\end{Verbatim}

Generating \texttt{sorted(A, B, Smaller')} and \texttt{sorted(A, C, Greater')}.
Furthermore, we can use the only rule that accepts \texttt{sorted} and
\texttt{waitpivot} facts:

\begin{Verbatim}[fontsize=\codesize]
waitpivot(A, Pivot, NodeSmaller, NodeGreater),
sorted(A, NodeSmaller, Smaller),
sorted(A, NodeGreater, Greater)
   -o reverse(A, Smaller, [], [Pivot | Greater]).
\end{Verbatim}

Returning \texttt{reverse(A, Smaller', [], [Pivot | Greater'])}. By applying the
reverse lemma, we get \texttt{reverse(A, [], Smaller'', [Pivot | Greater'])},
where \texttt{Smaller''} is the reverse of \texttt{Smaller'}.

Now, if we apply the only available rule for \texttt{reverse}, we get
\texttt{append(A, Smaller'', [Pivot | Greater'])}. Applying the append lemma, we
get \texttt{append(A, [], Smaller' ++ [Pivot | Greater'])} and then
\texttt{up(A, Smaller' ++ [Pivot | Greater']).}. We know that \texttt{Smaller'
++ [Pivot | Greater']} is sorted since \texttt{Small'} contains the sorted list
of elements \texttt{<= Pivot} and \texttt{Great'} the elements \texttt{> Pivot}.

\end{proof}

