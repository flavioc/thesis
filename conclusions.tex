
In this chapter, we summarize the main contributions of this thesis and suggest
several directions for further research.

\section{Main Contributions}

The goal of our thesis was to show the potential of using a forward-chaining
linear logic programming language to exploit parallelism in a declarative,
efficient and scalable way. For this, we designed and implemented LM, a
programming language suitable for writing concurrent algorithms over graph
data-structures. LM programs are composed of a set of inference rules that apply
over a database of logical facts. Concurrency is achieved by partitioning the
database across a graph data structures and forcing rule derivation to happen at
the node level. Since LM is based on linear logic, facts used in rules may be
retracted, making it possible for the programmer to declaratively manage
structured state.

We introduced coordination facts in LM to show that it is possible for the
programmer to change how programs are scheduled in order to improve program run
time and scalability. This is possible due to the existence of linear facts,
which make it possible for different scheduling decisions to have an effect on
program computation. Without them, a logic program would always compute the same
result.

We also introduced explicit parallelism in LM by adding support for thread
facts. Thread facts are facts stored at the thread level and allow the
programmer to write rules that reason about thread state. This opens new
opportunities for program optimization and improved parallelism because programs
are aware of the existence of threads. Furthermore, the availability of both
thread and coordination facts allows and is convenient for implementing more
sophisticated scheduling parallel algorithms.

We now highlight in more detail the main contributions of this dissertation:

\begin{description}
   \item[Structured State]

Since LM is based on linear logic, LM enables programs to manage state in a
structured manner. Due to the restriction over the inference rules, rules are
derived independently on different nodes of the graph data structure, which
makes it possible to run LM programs in parallel.

   \item[Implementation]

Writing efficient implementations of declarative languages is challenging,
especially when adding support for parallel execution. In this thesis, we have
shown a compilation strategy and memory layout organization for LM programs,
which allows programs to run less than one order of magnitude slower than
hand-written C++ programs. We also described how the LM runtime supports
multicore execution by partitioning the graph among threads. To the best of our
knowledge, LM is the fastest linear logic based programming language available.

\item[Semantics and Abstract Machine]

We showed how LM semantics are specified in order to allow concurrent
programs. We demonstrated how the language is based upon the sequent calculus of
linear logic and we specified a low level abstract machine that closely
resembles the real implementation. We also proved the soundness of the
abstract machine.

\item[Coordination]

We presented new coordination features that improve the expressive
power of the language by making coordination a first class programming construct
that is semantically equivalent to regular computation. In turn, this allows the
programmer to specify how declarative programs are scheduled by the runtime
system, therefore improving overall run time and scalability.

Coordination facts are divided into scheduling and partitioning facts.
Scheduling facts change how nodes are scheduled by the system while partitioning
facts change how nodes are assigned to threads and how they move between
threads. Both these two types of facts are divided into sensing facts (with
information about the state of the runtime system) and action facts (which
perform actions on the runtime system). The interplay between regular facts,
sensing facts and action facts results in faster execution time and improved
parallelism because regular facts affect how action facts are derived and,
conversely, action facts may affect which regular facts are derived.

The coordination facts do not affect the correctness of programs and are well
integrated into proofs since they do not change how rules are scheduled but how
nodes are scheduled during execution.

\item[Explicit Parallelism]

We also introduced the concept of thread facts, which enable LM programs to
exploit the underlying architecture by making it possible to reason about the
state of threads. Thread facts allow the programmer to escape the default
implicit parallelism of LM and allows the implementation of structured
scheduling algorithms which require explicit communication between threads.
To the best of our knowledge, this is the first time that such paradigm
is available in a logic programming language and we are not aware of competing
systems that allow the programmer to reason directly about thread state in a
structured fashion.

\item[Experimentation]

We compared LM sequential and multithreaded execution to hand-written sequential
C++ programs and against frameworks such as GraphLab and Ligra. We showed how
well the LM runtime is able to scale using different programs and datasets. We
measured the run time, scalability and memory usage effects of using
coordination facts and their overheads. For thread facts, we analyzed different
applications and measured the performance improvements of using explicit
parallelism.

In our experiments, we noted that the memory layout of applications, especially
the memory allocator, tends to have a significant effect on the overall
performance. In modern architectures, good memory locality is as important as
having efficient algorithms and in LM this is no different.
We experimented with two allocators to analyze how
performance and scalability may be affected by using different strategies. It is
our belief that it is important to focus on faster sequential execution at the
expense of scalability in order to make declarative parallel languages more
competitive with sequential programs written in languages such as C++.

\end{description}

\section{Future Work}

While much progress has been achieved with this thesis, many new research
avenues have been opened with this work. We now enumerate further research goals
that should be interesting to pursue.

\begin{description}
   \item[Faster Implementation]

LM is still not competitive enough to replace efficient parallel frameworks such
as Ligra. LM is a programming language on its own right and thus requires more
engineering effort to be competitive with frameworks implemented in languages
such as C or C++. Better compilation and runtime systems will be required in
order to reduce the overhead even further, especially as it relates to memory
usage.

Aggressive code analysis should be employed to prove invariants about predicates
and introduce more specialized data structures for storing logical facts. The
goal should be to recover more of the \emph{imperative flavor} that is present
in linear logic programs in order to make them more efficient. The restrictions
of LM rules that make concurrency possible makes this task harder since there is
an inherent tension between concurrency and execution speed since concurrency
implies communication. However, local node computation has still some room for
improvement.

\item[Provability]

We need automated tools for reasoning about correctness and termination of
programs. While we have shown that writing informal proofs is relatively easy
because programs tend to be small, automated proof systems will increase the
faith that programs will work correctly. Ideally, the programmer should be able
to write invariants about the program and the compiler should be able to prove
if such invariants are or are not being met with the given inference rules.

\item[Expressiveness]

Although LM programs are expressive, some work must be done in order to reduce
the restrictions on LM rules and allow for more programmer freedom.  LM
currently only allows rules where the LHS refers to the same node, however, it
should be possible to allow rules that use facts from different nodes. The use
of linear logic facts makes this hard because we need to ensure that a linear
fact is used only once, therefore the compiler should generate code to enforce
this, probably through the use of transactions. In the CHR community, Lam et
al.~\cite{Lam:2013:DEC:2505879.2505892} have developed an encoding for
distributed rules using at most one immediate neighbor into rules that run
locally. It should be relatively straightforward to provide a similar encoding
for LM and then assess how performance is affected by such encoding.

\item[Implicit and Explicit Parallelism] We need more applications that take
   advantage of the mixed parallelism that is available with thread facts. We
   feel that this paradigm needs to be further explored in order to make it
   possible to write new scheduling and parallel algorithms that could be
   compiled to efficient code in other application areas. Furthermore,
   mechanized proofs about such algorithms could then be automatic, improving
   the correctness and reliability of parallel algorithms.

\end{description}

\section{Final Remark}

We argue that our work makes LM the ideal framework for prototyping new
(correct) graph algorithms since LM programs tend to be relatively short and the
programmer only needs to reason about the state of the graph, without the need
to understand how the framework must be used to express the intended algorithms.
Furthermore, the addition of coordination facts and thread facts help the
programmer exploit the underlying parallel architecture in order to create
better programs that take advantage of those architectures without radically
changing the underlying parallel algorithm.  Finally, the good performance of
the LM system allows programs to run reasonably fast when executed on multicore
systems.

