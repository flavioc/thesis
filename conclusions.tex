
In this chapter, we summarize the main contributions of this thesis and suggest
several directions for further research.

\section{Main Contributions}

The goal of our thesis was to show the potential of using a forward-chaining
linear logic programming language to exploit parallelism in a declarative,
efficient and scalable way. For this, we designed and implemented LM, a
programming language suitable for writing concurrent algorithms over graph
data-structures. LM programs are composed of a set of inference rules that apply
over a database of logical facts.  Since LM is based on linear logic, facts used
in rules may be retracted, making it possible for the programmer to
declaratively manage structured state.

Concurrency is achieved by partitioning the database across a graph data
structure and then forcing rule derivation to happen at the node level. The use
of graphs allows LM to solve the task granularity problem that is common in
implicitly parallel languages. By localizing computation to nodes, it is
possible to group nodes together as sub-graphs that can be processed
independently. Even if certain sub-graph partitioning proves to have a poor task
balance, nodes of sub-graphs can be moved into other sub-graphs, allowing for
easy load balance between processing cores.

We introduced coordination facts in LM to allow the programmer to fine-tune and
optimize their declarative programs. This is possible due to the existence of
linear facts, which make it possible for different scheduling decisions to have
an effect on program computation. Without them, a logic program would always
compute the same result. Coordination facts are also another way to combat the
granularity problem since they allow the programmer to control how nodes are
grouped together.

We also introduced explicit parallelism in LM by adding support for thread
facts. Thread facts are facts stored at the thread level and allow the
programmer to write rules that reason about thread state. This opens new
opportunities for program optimization and improved parallelism because programs
are aware of the existence of threads. Furthermore, the availability of both
thread and coordination facts allows and is convenient for implementing more
sophisticated scheduling parallel algorithms.

We now highlight in more detail the main contributions of this dissertation:

\begin{description}
   \item[Structured State]

Since LM is based on linear logic, LM enables programs to manage state in a
structured manner. Due to the restriction over the inference rules, rules are
derived independently on different nodes of the graph data structure, which
makes it possible to run LM programs in parallel.

   \item[Implementation]

Writing efficient implementations of declarative languages is challenging,
especially when adding support for parallel execution. In this thesis, we have
shown a compilation strategy and memory layout organization for LM programs,
which allows programs to run less than one order of magnitude slower than
hand-written C++ programs. We also described how the LM runtime supports
multi core execution by partitioning the graph among threads. To the best of our
knowledge, LM is the fastest linear logic based programming language available.

\item[Semantics and Abstract Machine]

We showed how LM semantics are specified in order to allow concurrent
programs. We demonstrated how the language is based upon the sequent calculus of
linear logic and we specified a low level abstract machine that closely
resembles the real implementation. We also proved the soundness of the
abstract machine.

\item[Coordination]

We presented new coordination features that improve the expressive
power of the language by making coordination a first class programming construct
that is semantically equivalent to regular computation. In turn, this allows the
programmer to specify how declarative programs are scheduled by the runtime
system, therefore improving overall run time and scalability.

Coordination facts are divided into scheduling and partitioning facts.
Scheduling facts change how nodes are scheduled by the system while partitioning
facts change how nodes are assigned to threads and how they move between
threads. Both these two types of facts are divided into sensing facts (with
information about the state of the runtime system) and action facts (which
perform actions on the runtime system). The interplay between regular facts,
sensing facts and action facts results in faster execution time and improved
parallelism because regular facts affect how action facts are derived and,
conversely, action facts may affect which regular facts are derived.

The coordination facts do not affect the correctness of programs and are well
integrated into proofs since they do not change how rules are scheduled but how
nodes are scheduled during execution.

\item[Explicit Parallelism]

We also introduced the concept of thread facts, which enable LM programs to
exploit the underlying architecture by making it possible to reason about the
state of threads. Thread facts allow the programmer to escape the default
implicit parallelism of LM and allows the implementation of structured
scheduling algorithms which require explicit communication between threads.
To the best of our knowledge, this is the first time that such paradigm
is available in a logic programming language and we are not aware of competing
systems that allow the programmer to reason directly about thread state in a
structured fashion.

\item[Experimentation]

We compared LM sequential and multi threaded execution to hand-written sequential
C++ programs and against frameworks such as GraphLab and Ligra. We showed how
well the LM runtime is able to scale using different programs and datasets. We
measured the run time, scalability and memory usage effects of using
coordination facts and their overheads. For thread facts, we analyzed different
applications and measured the performance improvements of using explicit
parallelism.

In our experiments, we noted that the memory layout of applications, especially
the memory allocator, tends to have a significant effect on the overall
performance. In modern architectures, good memory locality is as important as
having efficient algorithms and in LM this is no different.
We experimented with two allocators to analyze how
performance and scalability may be affected by using different strategies. It is
our belief that it is important to focus on faster sequential execution at the
expense of scalability in order to make declarative parallel languages more
competitive with sequential programs written in languages such as C++.

\end{description}

\section{Drawbacks of LM}

While LM provides answers to several known problems in implicitly parallel
languages, it suffers from several disadvantages:

\begin{description}

   \item[Graph Of Nodes] Even though graph data structures are flexible and can
      be used to model many interesting problems, they are not always the best
      abstraction. Using graphs as an abstraction for concurrency requires
      some problems to be adapted to run on graphs in non intuitive
      ways. For instance, in the N-Queens problem in
      Section~\ref{section:coord:nqueens}, we had to map the chess board
      into a grid of nodes and then parallelize the program by considering each
      square as a unit that builds solutions to the problem. In general, the
      graph model of LM is suitable for irregular algorithms but not as suitable
      for regular algorithms such as numerical algorithms or algorithms that
      don't use graphs as their main data structure.

   \item[Thread Reasoning] Coordination facts and thread-based facts come with a
      cost when used to create complex scheduling algorithms because reasoning
      with coordinated programs requires that the programmer understands the
      semantics of the underlying virtual machine. However, we think it will be
      impossible to avoid this issue unless the runtime system performs all the
      optimizations, leaving no control to the programmer since optimization
      always requires some knowledge about the underlying hardware and software.
      In LM, the programmer pays a lower cost because the semantics of
      coordination provide a higher level of abstraction. Lastly, it remains to
      be shown if LM provides the right kind of abstraction for writing such
      programs.

   \item[Modularity] Program composition is still an unsolved problem in linear
      logic programming since it is hard to compose programs that manipulate the
      same state. Martens~\cite{chris-thesis} introduces the concept of staged
      logic programming which allows sets of logical rules to be grouped into
      stages. Each stage is computed separately and up to quiescence, allowing
      stages to have precedence over others. However, it still remains to be
      studied how separate rules can be grouped together without introducing
      conflicts.

\end{description}

\section{Future Work}

While much progress has been achieved with this thesis, many new research
avenues have been opened with this work. We now enumerate further research goals
that should be interesting to pursue.

\begin{description}
   \item[Faster Implementation]

LM is still not competitive enough to replace efficient parallel frameworks such
as Ligra. LM is a programming language on its own right and thus requires more
engineering effort to be competitive with frameworks implemented in languages
such as C or C++. Better compilation and runtime systems will be required in
order to reduce the overhead even further, especially as it relates to memory
usage.

Aggressive code analysis should be employed to prove invariants about predicates
and introduce more specialized data structures for storing logical facts. The
goal should be to recover more of the \emph{imperative flavor} that is present
in linear logic programs in order to make them more efficient. The restrictions
of LM rules that make concurrency possible makes this task harder since there is
an inherent tension between concurrency and execution speed since concurrency
implies communication. However, local node computation has still some room for
improvement.

\item[Provability]

We need automated tools for reasoning about correctness and termination of
programs. While we have shown that writing informal proofs is relatively easy
because programs tend to be small, automated proof systems will increase the
faith that programs will work correctly. Ideally, the programmer should be able
to write invariants about the program and the compiler should be able to prove
if such invariants are or are not being met with the given inference rules.

\item[Expressiveness]

Although LM programs are expressive, some work must be done in order to reduce
the restrictions on LM rules and allow for more programmer freedom.  LM
currently only allows rules where the LHS refers to the same node, however, it
should be possible to allow rules that use facts from different nodes. The use
of linear logic facts makes this hard because we need to ensure that a linear
fact is used only once, therefore the compiler should generate code to enforce
this, probably through the use of transactions. In the CHR community, Lam et
al.~\cite{Lam:2013:DEC:2505879.2505892} have developed an encoding for
distributed rules using at most one immediate neighbor into rules that run
locally. It should be relatively straightforward to provide a similar encoding
for LM and then assess how performance is affected by such encoding.

\item[Implicit and Explicit Parallelism] We need more applications that take
   advantage of the mixed parallelism that is available with thread facts. We
   feel that this paradigm needs to be further explored in order to make it
   possible to write new scheduling and parallel algorithms that could be
   compiled to efficient code in other application areas. Furthermore,
   mechanized proofs about such algorithms could then be automatic, improving
   the correctness and reliability of parallel algorithms.

\end{description}

\section{Final Remark}

We argue that our work makes LM the ideal framework for prototyping new
(correct) graph algorithms since LM programs tend to be relatively short and the
programmer only needs to reason about the state of the graph, without the need
to understand how the framework must be used to express the intended algorithms.
Furthermore, the addition of coordination facts and thread facts help the
programmer exploit the underlying parallel architecture in order to create
better programs that take advantage of those architectures without radically
changing the underlying parallel algorithm.  Finally, the good performance of
the LM system allows programs to run reasonably fast when executed on multi core
systems.

