
In this section, we present several LM programs in order to show that they tend to be concise and
easy to write. We also want to make clear how the language facilities can be used to solve more
complicated algorithms, including the quick-sort algorithm that at the first glance does not seem
to fit the graph based paradigm of LM.

\section{Bipartiteness Checking}

The problem of checking if a graph is bipartite can be seen as a 2-color graph coloring problem.
The code for this algorithm is shown in Fig.~\ref{code:bichecking}. All nodes in the graph
start as \texttt{unchecked}, because they do not have a color yet. The axiom \texttt{visit(@1, 1)} is
instantiated at node \texttt{@1} (line 9) in order to color this node with color 1.

If a node is \texttt{unchecked} and needs to be marked with a color \texttt{P} then the rule in
lines 11-12 is applied. We consume the \texttt{unchecked} fact and derive a \texttt{checked(A, P)}
to effectively color the node with \texttt{P}. We also derive \texttt{visit(B, next(P))} in
neighbor nodes to color them with the other color.

The coloring can fail if a node is already colored with a color \texttt{P} and needs to be colored
with a different color (line 15) or if it has already failed (line 16).

\begin{figure}[h!]
\small\begin{Verbatim}[numbers=left]
type route edge(node, node).
type linear visit(node, int).
type linear unchecked(node).
type linear checked(node, int).
type linear fail(node).

fun next(int X) : int = if X <> 1 then 1 else 2 end.

visit(@1, 1).

visit(A, P), unchecked(A)
   -o {B | !edge(A, B) | visit(B, next(P))}, checked(A, P).

visit(A, P), checked(A, P) -o checked(A, P).
visit(A, P1), checked(A, P2), P1 <> P2 -o fail(A).
visit(A, P), fail(A) -o fail(A).
\end{Verbatim}
  \caption{Bipartiteness Checking program.}
  \label{code:bichecking}
\end{figure}
\normalsize

\section{PageRank}

PageRank~\cite{Page:2001:MNR} is a well known graph algorithm that is used to compute the relative relevance of web pages.
The code for a synchronous version of the algorithm is shown in Fig.~\ref{code:pagerank}.
As the name indicates, the pagerank is computed for a certain number of iterations. The initial pagerank is the same for every page and is
initialized in the first rule (lines 15-16) along with an accumulator.

The second rule of the program (lines 18-22) propagates a newly computed pagerank value to all neighbors. Each node will then accumulate
the pagerank values that are sent to them through the fourth rule (lines 30-32) and it will immediately add other currently available values
through the use of the aggregate. When we have accumulated all the values we need, the third rule (lines 24-28) is fired and a new pagerank value is derived.

We also have an asynchronous version of the algorithm that trades correctness with convergence speed since it does not synchronize between iterations.

\begin{figure}[h!]
   \footnotesize\begin{Verbatim}[numbers=left]
type output(node, node, float).
type linear pagerank(node, float, int).
type numLinks(node, int).
type numInput(node, int).
type linear accumulator(node, float, int, int).
type linear newrank(node, node, float, int).
type linear start(node).

const damping = 0.85.
const iterations = str2int(@arg1).
const pages = @world.

start(A).

start(A), !numInput(A, T)
   -o accumulator(A, 0.0, T, 1), pagerank(A, 1.0 / float(pages), 0).

pagerank(A, V, Id), // propagate new pagerank value
!numLinks(A, C),
Id < iterations,
Result = V / float(C)
   -o {B, W | !output(A, B, W) | newrank(B, A, Result, Id + 1)}.

accumulator(A, Acc, 0, Id), // new pagerank
!numInput(A, T),
V = damping + (1.0 - damping) * Acc,
Id <= iterations
   -o pagerank(A, V, Id), accumulator(A, 0.0, T, Id + 1).
	
newrank(A, B, V, Id), accumulator(A, Acc, T, Id), T > 0
   -o [sum => S, count => C | D | newrank(A, D, S, Id) |
            1 | accumulator(A, Acc + V + S, T - 1 - C, Id)].
\end{Verbatim}
\caption{Synchronous PageRank program.}
\label{code:pagerank}
\normalsize
\end{figure}

\section{N Queens}

The N queens~\cite{8queens} puzzle is the problem of placing N chess queens on an NxN chessboard so
that no pair of two queens attack each other. The specific challenge of finding all the distinct
solutions to this problem is a good benchmark in designing parallel algorithms.

First, we consider each square of the chessboard as a node
that can communicate with the adjacent left, right and bottom squares, but not top square.
The states are represented as a list of integers, where each integer is the column number where
the queen was placed. For example $[2, 0]$ means that a queen is placed in square $(0, 0)$ and another in square $(1, 2)$.

An empty state is instantiated in the top-left node and is then propagated to all nodes in the same row.
Every node will then check if a queen can be placed on such square. If true, each node will send at most
two new states to the row below, one to the first non-diagonal column to the left and another to the column
in the right.
Recursively, when a node receives a new state, it will (i) send the state to the left
or to the right and (ii) try to place the queen in its square. With this method,
all states will be computed since we have facts for each valid state
at that point. When a suare cannot place a queen, that state is deleted.
When the program ends, all valid states will be placed in the bottom row.

We find our solution very elegant, since it can be easily executed in parallel and is an uncommon
approach to this problem.

\begin{comment}
\begin{figure}[h!]
\small\begin{Verbatim}[numbers=left]
type left(node, node).
type right(node, node).
type down(node, node).
type coord(node, int, int).
type linear propagate-left(node, list node, list int).
type linear propagate-right(node, list node, list int).
type linear receive-down(node, list node, list int).
type linear test-and-send-down(node, list node, list int).
type linear test-y(node, int, list int, list node, list int).
type linear test-diag-left(node, int, int, list int, list node, list int).
type linear test-diag-right(node, int, int, list int, list node, list int).
type linear send-down(node, list node, list int).
type linear final-state(node, list node, list int).

const size = 11.

receive-down(@0, [], []).

receive-down(A, Nodes, Coords)
   -o {R | !right(A, R), R <> A | propagate-right(R, Nodes, Coords)},
      {L | !left(A, L), L <> A | propagate-left(L, Nodes, Coords)},
      test-and-send-down(A, Nodes, Coords).

propagate-left(A, Nodes, Coords)
   -o {L | !left(A, L), L <> A | propagate-left(L, Nodes, Coords)},
      test-and-send-down(A, Nodes, Coords).

propagate-right(A, Nodes, Coords)
   -o {R | !right(A, R), R <> A | propagate-right(R, Nodes, Coords)},
      test-and-send-down(A, Nodes, Coords).

test-and-send-down(A, Nodes, Coords),
!coord(A, X, Y)
   -o test-y(A, Y, Coords, Nodes, Coords).

test-y(A, Y, [], Nodes, Coords), !coord(A, OX, OY) -o test-diag-left(A, OX - 1, OY - 1, Coords, Nodes, Coords).
test-y(A, Y, [X, Y1 | RestCoords], Nodes, Coords), Y = Y1 -o 1. // fail
test-y(A, Y, [X, Y1 | RestCoords], Nodes, Coords), Y <> Y1 -o test-y(A, Y, RestCoords, Nodes, Coords).

test-diag-left(A, X, Y, _, Nodes, Coords),
X < 0 || Y < 0,
!coord(A, OX, OY)
   -o test-diag-right(A, OX - 1, OY + 1, Coords, Nodes, Coords).

test-diag-left(A, X, Y, [X1, Y1 | RestCoords], Nodes, Coords),
X = X1, Y = Y1
   -o 1. // fail

test-diag-left(A, X, Y, [X1, Y1 | RestCoords], Nodes, Coords),
X <> X1 || Y <> Y1
   -o test-diag-left(A, X - 1, Y - 1, RestCoords, Nodes, Coords).

test-diag-right(A, X, Y, [], Nodes, Coords),
X < 0 || Y >= size,
!coord(A, OX, OY)
   -o send-down(A, [A | Nodes], [OX, OY | Coords]).

test-diag-right(A, X, Y, [X1, Y1 | RestCoords], Nodes, Coords),
X = X1, Y = Y1
   -o 1. // fail

test-diag-right(A, X, Y, [X1, Y1 | RestCoords], Nodes, Coords),
X <> X1 || Y <> Y1
   -o test-diag-right(A, X - 1, Y + 1, RestCoords, Nodes, Coords).

send-down(A, Nodes, Coords),
!down(A, A)
   -o final-state(A, Nodes, Coords).
   
send-down(A, Nodes, Coords),
!down(A, B),
A <> B
   -o receive-down(B, Nodes, Coords).
\end{Verbatim}
  \caption{Visit program.}
  \label{code:visit}
\end{figure}
\normalsize
\end{comment}

\section{Quick-Sort}

The quick-sort algorithm is a divide and conquer sorting algorithm that works by splitting
a list of items into two sublists and then recursively sorting the two sublists.
To split the list, we pick a pivot element and put the items that are smaller than the pivot
into the first sublist and items greater than the pivot into the second list.

The quick-sort algorithm is interesting because it does not map immediately to the graph-based
model of LM. Our approach considers that the program starts with a single node where
the initial list is located. Then we split the list as usual and create two nodes
that will recursively sort the sublists. Interestingly, this will create a tree
that will look similar to a call tree in a functional language.

Fig.~\ref{code:quicksort} presents the code for the quick-sort algorithm in LM.
For each sublist to sort, we start with a \texttt{down} fact that must be (eventually)
transformed into an \texttt{up} fact, where the sublist in the \texttt{up} fact is sorted.
In line 11 we start with the initial list at node \texttt{@0}. Lines 13-16 will immediately
sort the list when the number of items is very small. Otherwise, we apply the rule in line 17.
\texttt{buildpivot} will first split the list using the pivot \texttt{X} using rules in
lines 23-26. When there is nothing more to split, we apply the rule in lines 19-21
that uses an exist construct to create nodes \texttt{B} and \texttt{C}. The sublists
are then sent to these nodes using \texttt{down} facts. Note, however, that we also
derive \texttt{back} facts, that will be used to send the sorted list back using the rule
in line 40.

When the sublists are finally sorted, we get two \texttt{sorted} facts that will match
against \texttt{waitpivot} in the rule located in lines 28-31. The sorted sublists
are appended and then an \texttt{up} fact is finally derived (line 37).

\begin{figure}[h!]
\small\begin{Verbatim}[numbers=left]
type route back(node, node).
type linear down(node, list int).
type linear up(node, list int).
type linear sorted(node, node, list int).
type linear buildpivot(node, list int, int, list int, list int).
type linear waitpivot(node, node, node, int).
type linear append(node, list int, list int).
type linear reverse(node, list int, list int, list int).
type linear reverse2(node, list int, list int).

down(@0, tosort).

down(A, []) -o up(A, []).
down(A, [X]) -o up(A, [X]).
down(A, [X, Y]), X < Y -o up(A, [X, Y]).
down(A, [X, Y]), X >= Y -o up(A, [Y, X]).
down(A, [X | L]) -o buildpivot(A, L, X, [], []).

buildpivot(A, [], X, Smaller, Greater)
   -o exists B, C. (back(B, A), down(B, Smaller),
            back(C, A), down(C, Greater), waitpivot(A, B, C, X)).

buildpivot(A, [Y | L], X, Smaller, Greater), Y <= X
   -o buildpivot(A, L, X, [Y | Smaller], Greater).
buildpivot(A, [Y | L], X, Smaller, Greater), Y > X
   -o buildpivot(A, L, X, Smaller, [Y | Greater]).
   
waitpivot(A, NodeSmaller, NodeGreater, Pivot),
sorted(A, NodeSmaller, Smaller),
sorted(A, NodeGreater, Greater)
   -o append(A, Smaller, [Pivot | Greater]).

append(A, L1, L2) -o reverse(A, L1, L2, []).

reverse(A, [], L2, L3) -o reverse2(A, L3, L2).
reverse(A, [X | L], L2, L3) -o reverse(A, L, L2, [X | L3]).
reverse2(A, [], Result) -o up(A, Result).
reverse2(A, [X | L1], L2) -o reverse2(A, L1, [X | L2]).

up(A, L), back(A, B) -o sorted(B, A, L).
\end{Verbatim}
  \caption{Quick-Sort program.}
  \label{code:quicksort}
\end{figure}
\normalsize


\section{MiniMax}

\section{Heat Transfer}

\section{Belief Propagation}

\section{Belief Propagation with Splashes}
