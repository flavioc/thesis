\section{Parallel Programming}

\section{Declarative Programming}

Logic and functional programming languages are a major class of languages called
declarative programming languages. Logic programming languages are usually based
on classical logic (such as the \emph{predicate and propositional calculus}) or
in non-classical logics such as \emph{constructive} or \emph{intuitionistic}
logic, where the goal is to construct different models of logical truth.  In the
other hand, functional programming languages are usually based on the
\emph{lambda calculus}, a model for function application and abstraction. As
declarative languages, logic and functional programming languages are considered
to be high-level languages when compared to imperative languages because,
generally, they allow the programmer to concentrate more on what the problem is,
rather than telling the computers the steps it needs to do to solve the problem.
In turn, this allows for a simplified formal reasoning about important program
properties such as correctness and termination.

\paragraph{Logic Programming}

Logical systems define their own meaning of truth and a set of rules that
manipulate truth in order to create proofs inside the system.  For instance, the
system of \emph{propositional logic} contains the \emph{modus ponens} rule,
where truth is manipulated as follows: if $P$ implies $Q$ and $P$ is known to be
true, therefore $Q$ must also be true. If we know that ``it is raining'' and
that ``if it is raining then the grass is wet'', we can prove that ``the grass
wet'' by using the \emph{modus ponens} rule.

Logic programming arises when the proof search strategy in a logical system is
fixed. In the case of propositional logic, we can devise the following
programming model:

\begin{itemize}
   \item A set $R$ of implications of the form ``$P$ implies $Q$'' represents the
      program;
   \item A set of atomic truths $D$ of the form ``$P$'' represents the database of
      known truths;
   \item Proof search is done by applying implications in $R$ using the truth
      stored in $D$ and adding new truths from the application of \emph{modus
      ponens} into $D$.
\end{itemize}

This particular proof search mechanism is called \emph{forward-chaining} logic
programming, since it starts from the \emph{axioms} (the initial truths) and
then uses inference rules (\emph{modus ponens}) to accumulate more truth. The
proof search may then stop if the search has found a particular proposition to
be true or if it is not possible to derive any more truths, which is called
\emph{quiescence}.

An alternative proof search strategy is \emph{backward-chaining} logic
programming. In this style of programming, we want to know if a particular
proposition is true and then work backwards using the inference rules. For
instance, consider the implications: (1) ``if the it is raining then the grass
is wet'' and (2) ``if the weather forecast for today is rain then it is raining''
and the proposition (3) ``the weather forecast for today is rain''. If we want
to know if (4) ``the grass is wet'', we select the implication (1) and attempt to prove
``it is raining'' since it is required by (1) to prove (4), the goal
proposition. Next, the goal proposition becomes ``it is raining'' and the
conclusion of implication (2) matches and thus we have to prove ``the weather
forecast for today is rain'', which can be proved immediately using axiom (3).

Prolog~\cite{Colmerauer:1993:BP:154766.155362} is one of the first logic
programming languages to become available, yet it still one of the most popular
logic programming language in use today. Prolog is based on \emph{First Order
Logic}, a logical system that extends propositional logic with predicates and
variables. Prolog is a backward-chaining logic programming language where a
program is composed of a set of rules that can be activated by inputing a query.
Given a query $q(\hat{x})$, a Prolog interpreter will work backwards by matching
$q(\hat{x})$ against the head of a rule. If found, the interpreter will then try
to match the body of the rule, recursively, until it finds the program axioms
(rules without body). If the search procedure succeeds, the interpreter finds a
valid substitution for the $\hat{x}$ variables.

Datalog~\cite{Ramakrishnan93asurvey,Ullman:1990:PDK:533142} is a
forward-chaining logic programming language originally designed for deductive
databases. Datalog has been traditionally used in deductive databases, but is
now being increasingly used in other fields such as sensor
nets~\cite{Chu:2007:DID:1322263.1322281}, cloud computing~\cite{alvaro:boom},
and social networks~\cite{Seo:2013:DSD:2556549.2556572}.  In Datalog, the
program is composed of a database of facts and a set of rules.  Datalog programs
first populate the database with axioms and then saturate the database using
rule inference. In Datalog, logical facts are persistent and thus once a fact is
derived, it cannot be deleted. However, there has been a growing interest in
integrating linear logic~\cite{girard-87} into bottom-up logic programming,
allowing for both fact assertion and
retraction~\cite{Chang03ajudgmental,Lopez:2005:MCL:1069774.1069778,simmons-lla,cruz-iclp14},
which is one of the topics of this thesis.

\paragraph{Declarative Programming and Parallel Programming}

In functional programming languages, the \emph{side-effect free} nature of
computation allows multiple expressions to evaluate safely in
parallel~\cite{Loidl:2003}. This so called \emph{implicit parallelism} has been
implemented in languages such as Id~\cite{Nikhil93anoverview} and
SISAL~\cite{gaudiot2001sisal} with relative success but this kind of parallelism
remains elusive in the functional programming community since practical
functional programs have a higher level of granularity, which makes it harder
for a compiler to schedule computations efficiently~\cite{haskell_tutorial}.

Alternative approaches such as \emph{semi-explicit
parallelism}~\cite{Marlow:2010}, \emph{nested data
parallelism}~\cite{Blelloch:1996:PPA:227234.227246}, and \emph{software
transactional memory} have shown to be more effective in practice. In
semi-explicit parallelism, the programmer uses an API to tell the runtime system
which computations should be carried out in parallel, reducing the granularity
problem found in implicit parallelism. These parallel
computations are called \emph{sparked computations} and express the possibility
of performing speculative computations which are going to be needed in the
future. In a sense, sparked computations can be seen as \emph{lazy
futures}~\cite{Baker:1977}.

This has been initially explored in several languages, such as
NESL~\cite{Blelloch:1996:PPA:227234.227246} or Id~\cite{Nikhil93anoverview}, and
later implemented in more modern languages such as
Haskell~\cite{Chakravarty07dataparallel}.

In logic programming languages such as Prolog, researchers took advantage of the
non-determinism of proof-search to evaluate subgoals in parallel. The most
famous models are \emph{OR-parallelism} and
\emph{AND-parallelism}~\cite{Gupta:2001:PEP:504083.504085}. When performing
proof search with two implications of the form ``$P$ implies $Q$'' and ``$R$
implies $Q$'' then we have OR-parallelism because proof search can select ``$P$
implies $Q$'' and try to prove $P$ but also select ``$R$ implies $Q$'' and prove
$R$. In AND-parallelism, there is an implication of the form ``$P$ and $R$
implies $Q$'' then to prove $Q$, it is possible to prove $P$ and $Q$ at the same
time. AND-parallelism becomes more complicated when $P$ and $Q$ actually depend
on each other, that is, if $P = \mathtt{prop}_1(X)$ and $R = \mathtt{prop}_2(X,
Y)$ then the variable $X$ must be the same in the two predicates. This issue
does not arise in OR-parallelism, however AND-parallelism may be better when
rules are more deterministic (less options).

In Datalog programs, parallelism arises naturally because new logical facts may
activate multiple inference rules and thus generate more
facts~\cite{Ganguly:1990:FPP:93597.98724,Seib:1991:PDP:113413.113435,Wolfson:1988:DPL:971701.50242}.
A trivial parallelization can be done by splitting the rules among processing
units, however this may require sharing of logical facts depending on the rule
partitioning~\cite{Wolfson:1988:DPL:971701.50242}. Another alternative is to
partition the logical facts among the
machines~\cite{183073,Loo-condie-garofalakis-p2}, where rules are restricted in
order to facilitate fact partitioning and communication. The LM language
presented in this thesis follows this particular approach.

\paragraph{Origins of LM}

LM is a direct descendant of Meld, a logic programming language developed by
Ashley-Rollman et
al.~\cite{ashley-rollman-iclp09,ashley-rollman-derosa-iros07wksp} in the context
of the Claytronics project~\cite{goldstein-computer05}. Meld is a language
suited for programming massively dynamic distributed systems made of modular
robots. While mutable state is not supported by Meld, Meld performs \emph{state
management} on the persistent facts by keeping a consistent database of facts
whenever there is a change in the axioms. If an axiom is no longer true,
everything derived from that axiom is retracted. Likewise, when a fact becomes
true, the database is immediately updated to take the new logical fact into
account. To take advantage of these state management facilities, Meld supports
\emph{sensing} and \emph{action} facts. Sensing facts are axioms derived from
the state of the world (e.g., temperature, new neighbor node) and action facts
are facts that have an effect on the world (e.g., move), changing the underlying
sensing facts.

Meld was inspired in the P2 system~\cite{Loo-condie-garofalakis-p2}, which
includes a logic programming language called NDlog for writing network
algorithms declaratively. Many ideas about state management were already present
in NDlog.  NDlog is essentially a Datalog based language with a few extensions
for declarative networking.

\paragraph{Data-Centric Languages}

Recently, there has been an increasing interest in declarative data-centric
languages. MapReduce~\cite{Dean:2008:MSD:1327452.1327492}, for instance, is a
popular data-centric programming model that is optimized for large clusters. The
scheduling and data sharing model is very simple: in the \emph{map phase}, data
is transformed at each node and the result reduced to a final result in the
\emph{reduce phase}. In order to facilitate the writing of programs over large
datasets, SQL-like languages such as
PigLatin~\cite{Olston:2008:PLN:1376616.1376726} have been developed. PigLatin
builds on top of MapReduce and allows the programmer to write complex data-flow
graphs, raising the abstraction and ease of programmability of MapReduce
programs. An alternative to PigLatin/MapReduce is
Dryad~\cite{Isard:2007:DDD:1272996.1273005} that allows programmers to design
arbitrary computation patterns using DAG abstractions. It combines computational
vertices with communication channels (edges) that are automatically scheduled to
run on multiple computers/cores.

\section{Provability}

Many techniques and formal systems have been devised to help reason about
parallel programs.  One such example is the
Owicki-Gries~\cite{Owicki:1976:VPP:360051.360224} deductive system for proving
properties about imperative parallel programs (deadlock detection, termination,
etc). It extends Hoare logic with a stronger set axioms such as parallel
execution, critical section and auxiliary variables. The formal system can be
successfully used in small imperative programs, although using it on languages
such as C is difficult since they do not restrict the use of shared variables.

Some formal systems do not build on top of a known programming paradigm, but
instead create an entirely new formal system for describing concurrent systems.
Process calculus such as $\pi$-calculus~\cite{Milner:1999:CMS:329902} is a good
example of this.  The $\pi$-calculus describes the interactions between
processes through the use of channels for communication. Interestingly, channels
can also be transmitted as messages, allowing for changes in the network of
processes.  Given two processes, $\pi$-calculus is able to prove that they
behave the same through the use of bi-simulation equivalence.

Another interesting model is Mobile UNITY~\cite{Roman97anintroduction}. The
basic UNITY~\cite{UNITY} model assumes that statements could be executed
non-deterministically in order to create parallelism. This principle is applied
to prove properties about the system.  Mobile UNITY transforms UNITY by adding
locations to processes and removing the nondeterministic aspect from local
processes. Processes could then communicate or move between locations.

The Meld language, as a logic programming language, has been used to produce
proofs of correctness. Meld program code is amenable to mechanized analysis via
theorem checkers such as Twelf~\cite{twelf}, a logic system designed for
analyzing program logics and logic program implementations.  For instance, a
meta-module based shape planner program was proven to be
correct~\cite{dewey-iros08,ashley-rollman-iclp09} under the assumption that
actions derived by the program are always successfully applied in the outside
world.  While the fault tolerance aspect is lax, the planner will always reach
the target shape in finite time.  The sketch of the proof is presented in Dewey
et al.~\cite{dewey-iros08}

