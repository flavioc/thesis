The Low Level Dynamic~(LLD) semantics remove all the non-deterministic choices
in the previous dynamics and makes them deterministic. The new semantics will do
the following:

\begin{itemize}

   \item Match rules by priority order;

   \item Determine the set of linear facts needed to match either the body of
   the rule or the body of comprehensions/aggregates without guessing;

   \item Apply as many comprehensions as the database allows.

   \item Apply as many aggregates as the database allows.

\end{itemize}

The complete set of inference rules for the semantics are presented in
Appendix~\ref{sec:lld}.

LLD is specified as an \emph{abstract machine} and is represented as a sequence
of state transitions of the form $\trans{S_1}{S_2}$. HLD had many different
proof trees for a given triplet $\Gamma; \Delta; \Phi$ because HLD allows
choices to be made during the inference rules. For instance, in HLD any rule
could be selected to be executed.  In LLD there is only one state sequence
possible for a given $\Gamma; \Delta; \Phi$ since there is no guessing involved.
LLD semantics present a complete step by step mechanism that is needed to
correctly evaluate a LM program. For instance, when LLD tries to apply a rule,
it will check if there is enough facts in the database and backtrack
until a rule can be applied.

\subsection{Application}

LLD shares exactly the same inputs and outputs as HLD. The first difference
between the two systems starts when picking a rule to derive.  Instead of
guessing, LLD treats the list of rules as a stack and picks the first rule $R_1$
to execute (the rule with the highest priority). The remaining rules are stored
as a \emph{continuation}. If $R_1$ cannot be matched because there is not enough
facts in the database, we backtrack and use the rule continuation to pick the
next rule and so on, until one rule can be successfully applied.

The machine starts with a database $(\Gamma; \Delta)$ and a queue of rules
$\Phi$. The initial state is always $\dostate{\Delta}{\Phi}{\Gamma}{\Pi}$.
We start by picking the first rule $R_1$ from $\Phi$:

\input{lld/application}

\subsection{Continuation Frames}

The most interesting aspects introduced by the LLD machine are the \emph{continuation frame}
and the \emph{continuation stack}. A continuation frame acts as a choice point
that is created during rule matching whenever we try to match a fact expression
against the database.  The frame considers all the facts relevant to the
expression given the current variable bindings and predicate, that may or not
fail during the remaining matching process.

The frame contains enough state to resume the matching process at the time of
its creation, therefore we can easily backtrack to the choice point and select
the next candidate fact from the database.
We keep the continuation frames in a continuation stack for backtracking
purposes. If a given fact fails, we update the top frame to try the next
candidate fact. If all candidates are exhausted, we pop the top frame and
continue with the next available frame.

By using this match mechanism, we determine which facts need to be used to match
a rule.  Our LM implementation works like LLD, by iterating over the available
facts at each choice point and then committing to the rule if the matching
process succeeds. However, while the implementation only attempts to match rules
with a very high change of success, LLD is more na\"{i}ve in this aspect because
it tries all rules in order.


\subsection{Structure of Continuation Frames}

We have two continuation frame types, depending on the type of the candidate
facts.\footnote{All continuation frames have an implicit $\Psi$ context that
models variable assignments, including variable names, values and their
locations in the terms. This is important if we want to model variable
assignments and matchings.}

\subsubsection{Linear Continuation Frames}

There are two types of continuation frames. Linear frames use the form
$\lframe{\Delta}{\Delta''}{p}{\Omega}{\Delta'}{\Omega}$, where:

\begin{description}
   \item[$\Delta$] multi-set of linear facts that are not of type $p$ plus all
   the other $p$'s we have already tried, including the current $p$;

   \item[$\Delta''$] all the other $p$'s we haven't tried yet. It is a multi-set
   of linear facts;

   \item[$p$] current fact expression that originated this choice point;

   \item[$\Omega$] ordered list of remaining terms needed to match past this
   choice point;

   \item[$\Delta'$] multi-set of linear facts we have consumed to reach this point;

   \item[$\Omega'$] terms matched up-to this point using $\Delta'$ and $\Gamma$.
\end{description}

\subsubsection{Persistent Continuation Frame}

Persistent frames are slightly different since they only need to keep track of
remaining persistent candidates. They are structured as $\pframe{\Gamma''}{\Delta}{\bang
   p}{\Omega}{\Delta'}{\Omega'}$:

\begin{description}
   \item[$\Gamma''$] remaining candidate facts;
   \item[$\Delta$] remaining multi-set of linear facts;
   \item[$\bang p$] current fact expression that originated this choice point;
   \item[$\Omega$] ordered list of remaining terms needed to match past this
   choice point;
   \item[$\Delta'$] multi-set of linear facts consumed up-to this point;
   \item[$\Omega'$] terms matched up-to this point using $\Delta'$ and $\Gamma$.
\end{description}


\subsection{Match}\label{sec:lld_body_match}

The matching state for the LLD machine uses the continuation stack to try
different combinations of facts until a match is achieved.  The state is
structured as $\matstate{A \lolli
   B}{\rulestk}{\lstack{C}}{\Gamma}{\Delta}{\Omega}{\Delta' \rightarrow
      \Omega'}$, where:

\begin{description}
   \item[$A \lolli B$] rule being matched: $A$ is the body and $B$ the head;

   \item[$\rulestk$] rule continuation to be used if the current rule fails.
   Contains the original $\Delta_N$ and the rest of the rules $\Phi$;

   \item[$\lstack{C}$] ordered list of frames representing the continuation
   stack used for matching $A$;

   \item[$\Delta$] multi-set of linear facts still available to complete the
   matching process;

   \item[$\Omega$] ordered list of deconstructed head terms to match;

   \item[$\Delta'$] multi-set of linear facts from the original $\Delta_N$ that
   were already consumed ($\Delta', \Delta = \Delta_N$);

   \item[$\Omega'$] parts of $A$ already matched. They are in the form $P_1
   \otimes \dotsb \otimes P_n$. The idea is to use term equivalence and the fact
   that $\feq{\Omega, \Omega'}{A}$ to justify $\mz{\Gamma}{\Delta'}{A}$ when the
   matching process completes.

\end{description}

Matching will attempt to use facts from $\Delta$ and $\Gamma$ to match the terms
of the body of the rule represented as $\Omega$. During the process
continuation frames are pushed into $\lstack{C}$ and if the matching process
fails, we use $\lstack{C}$ to restore the process using different
candidate facts.

\subsubsection{Linear fact expression}

The first 2 state transitions are used when the head of $\Omega$ is a linear fact
expression $p$.

In the first transition we find $p_1$ and $\Delta''$ as facts from the database
that match $p$'s hidden and partially initialized arguments.  Context $\Delta''$
is stored in the second argument of the new continuation frame but is passed
along with $\Delta$ since the facts have not been consumed yet (just $p_1$).

The second transition deals with the case where there are no candiate facts and
thus a different machine state is used for enabling backtracking.

Note that the proposition $p_1, \Delta'' \prec p$ indicates that facts
$\Delta'', p_1$ satisfy the constraints of $p$ while $\Delta \npreceq p$
indicates that no fact in $\Delta$ satisfies $p$.

\input{lld/match-p}

\subsubsection{Persistent fact expressions}

The next 2 state transitions are used when the head of $\Omega$ contains a
persistent fact expression $\bang p$. They are identical to the previous 2
transitions but they deal with the persistent context $\Gamma$.

\input{lld/match-bang-p}

\subsubsection{Other expressions}

Finally, we have the transitions that deconstruct the other body terms and a
final transition to initiate the derivation of head due to a successful match.

\input{lld/match-other}

\subsection{Backtracking}\label{sec:lld_match_cont}

The backtracking state of the machine reads the top of the continuation stack
$\lstack{C}$ and restores the matching process with a different candidate fact
from the continuation frame. The state is written as $\contstate{A \lolli
B}{\rulestk}{\lstack{C}}{\Gamma}$, where:

\begin{description}
   \item[$A \lolli B$] the rule being matched;
   \item[$\rulestk$] next available rules if the current rule does not match;
   the rule continuation;
   \item[$\lstack{C}$] the continuation stack for matching body $A$;
\end{description}

\subsubsection{Linear continuation frames}

The next two state transitions handle linear continuation frames on the top of the
continuation stack. The first transition selects the next candidate fact $p_1$ from the
second argument of the linear frame and updates the frame. Otherwise, if we have
no more candidate facts, we pop the continuation frame and backtrack to the
remaining continuation stack.

\input{lld/cont-p}

\subsubsection{Persistent continuation frames}

We also have the same two kinds of inference rules for persistent continuation
frames.

\input{lld/cont-bang-p}

\subsubsection{Empty continuation stack}

Finally, if the continuation stack is empty, we simply force execution to try
the next inference rule in $\Phi$.

\input{lld/cont-empty}

\subsection{Derivation}

Once the list of terms $\Omega$ of the body is exhausted, we derive the head of
rule.  The derivation state simply iterates over $B$, the head of the rule, and
derives terms into the corresponding new contexts. The state is represented as
$\derstatex{\Gamma}{\Delta}{\Xi}{\Gamma_1}{\Delta_1}{\Omega}$ with the following meaning:

\begin{enumerate}
   \item[$\Gamma$] set of persistent facts;

   \item[$\Delta$] multi-set of remaining liner facts;

   \item[$\Xi$] multi-set of linear facts consumed up-to this point;

   \item[$\Gamma_1$] set of persistent facts derived;

   \item[$\Delta_1$] multi-set of linear facts derived;

   \item[$\Omega$] remaining terms to derive as an ordered list. We start with
   $B$ if the original rule is $A \lolli B$.

\end{enumerate}

\subsubsection{Fact templates}

When deriving either $p$ or $\bang p$ we have the following two inference rules:

\input{lld/der-p}

\subsubsection{Deconstruct head}

The following two inference rules deconstruct the head list $\Omega$ from terms
created using either $\one$ or $\otimes$.

\input{lld/der-other}

\subsubsection{Aggregates}

We also have a transition for aggregates. The aggregate starts with a set of
values $\widehat{V}$ and an accumulator initialized as $\cdot$. The second state
initiates the matching process of the body $A$ of the aggregate (explained in
the next section).

\input{lld/der-agg}

\subsubsection{Successful rule}

Finally, if the ordered list $\Omega$ is exhausted, then the whole execution
process is done.  Note how the output arguments match the input arguments of the
$\done$judgment.

\input{lld/der-done}

\subsection{Aggregates}

\input{lld/aggregates}

