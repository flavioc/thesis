
As mentioned in Section~\ref{sec:background:coordination}, Linda~\cite{linda}
and Delirium~\cite{Delirium} are two programming languages that support
coordination. When compared to LM, Linda and Delirium are limited in the sense
that the programmer can only coordinate the scheduling of processing units,
while placement of data is left to the implementation. LM differs from those
languages because coordination acts on data instead of processing units.
Coordination facts as used in this chapter raise the abstraction by considering
data and algorithmic aspects of the program instead of focusing on how
processing units are used. Furthermore, LM is both a coordination language and a
computation language and there is no distinction between the two components.

There are also several programming models also support some kind of coordination
primitives that allow explicit scheduling and load balancing of work between
available processing units but are not considered proper programming languages.

The Galois~\cite{Pingali:2011:TPA:1993316.1993501} programming model implements
autonomous scheduling by default, where activities may be rolled back in case of
conflict. However, it is possible to employ a concrete scheduling strategy for
coordinating parallel execution in order to improve execution and avoid
conflicts.  First, there is \emph{compile-time coordination}, where the
scheduling ordered is computed during compilation and is pre-defined before the
program is executed. Secondly, there is \emph{runtime coordination}, where the
order of activities is computed during execution. The execution of the algorithm
proceeds in rounds: first, a set of non-conflicting activities is computed and
then executed by applying the operator; conflicting activities are postponed to
the next round. The third and last scheduling strategy is \emph{just-in-time
coordination} where the order of activities is defined by the underlying data
structure where the operator is applied (for instance, computing on a graph
may depend on its topology).

In the context of the Galois model, Nguyen et al.~\cite{nguyen11} expanded the
concept of runtime coordination with the introduction of a flexible approach to specify
scheduling policies for Galois programs. This approach was motivated by the fact
that some algorithms can be executed faster if computations use better
scheduling strategies. The scheduling language specifies 3 main scheduler types:
FIFO (First-In First-Out), LIFO (Last-In First-Out) and
OrderedByMetric (order activities by some metric). These schedulers can
be composed and synthesized without requiring users to write complex concurrent
code.

Elixir~\cite{Prountzos:2012:ESS:2384616.2384644} is a domain specific language
that builds on top of the Galois and allows easy specification of scheduling
strategies.  The main idea behind Elixir is that the user should be able to
specify how operator application is scheduled and the framework will compile
this high level specification to low level code using the provided scheduling
specification. One of the motivating examples is the Single Source Shortest Path
program that can be specified using multiple scheduling specifications,
generating different well-known shortest path algorithms such as the
Dijkstra or Bellman-Ford algorithm. Unlike the work of Nguyen et
all.~\cite{nguyen11}, Elixir does not allow graph mutations.

Halide~\cite{Ragan-Kelley:2013:HLC:2491956.2462176} is a language and compiler
for image processing pipelines with the goal of optimizing parallelism, locality
and re-computation. Halide decouples the algorithm definition from its execution
strategy, allowing the compiler to find which execution strategy may be the best
for optimizing for locality and parallelism. The language allows the programmer
to specify the scheduling strategy, allowing the programmer to decide the order
of computations, what intermediate results need to be stored, how to split the
data among processing units and how to use vectorization and the well-known
sliding window mechanism. However, the compiler is able to use stochastic search
to find good schedules for Halide pipelines. Notably, experimental results
indicate that automatic search sometimes leads to better execution than
hand-written code.

In contrast to the previous systems, LM stands alone in making coordination
(both scheduling and partitioning) a first-class programming construct and
semantically equivalent to computation. Furthermore, LM distinguishes itself by
supporting data-driven dynamic coordination, particularly for irregular data
structures. Elixir and Galois do not support coordination for data partitioning,
and, in Elixir, the coordination specification is separated from computation,
limiting the programmability of coordination. Compared to LM, Halide is
targeted for regular applications and therefore only supports compile time
coordination.
