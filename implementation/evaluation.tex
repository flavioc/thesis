In this section, we evaluate the performance and scalability of the VM. The main
goals of this evaluation are as follows:

\begin{itemize}
   \item Compare the performance of LM programs against hand-written
      imperative C++ programs;
   \item Evaluate the scalability of said LM programs when using up to 20 cores
      concurrently;
   \item Understand the impact and effectiveness of our dynamic indexing
      algorithm and its indexing data structures used for logical facts (namely,
      hash tables);
   \item Understand the impact of the thread allocator and fact allocator on scalability and
      multicore performance;
\end{itemize}

For our experimental setup, we used a computer with a 24 (4x6) Core AMD
Opteron(tm) Processor 8425 HE $@$ 800 MHz with 64 GBytes of RAM memory running
the Linux Kernel 3.15.10-201.fc20.x86\_64. The C++ compiler used is the GCC
4.8.3 (g++) with the following \code{CXXFLAGS} flags: \code{-O3 -std=c++11
-march=x86-64}.  All experiments were executed 3 times and the running times
were averaged.

\subsection{Performance}

To understand the absolute performance of LM programs, we measured their
``sequential'' performance using a single thread of execution against
hand-written sequential C++ programs. All C++ programs were compiled with the
compilation flags that were used for LM in order to improve fairness. Arguably,
compiled C/C++ programs are a good standard for understanding the baseline
performance of new language runtimes, since compiled C/C++ programs tend to come
up on top on several popular programming language
benchmarksi~\cite{language_benchmarks}.  Furthermore, the performance of
sequential C++ programs is a better baseline for measuring the scalability of LM
since these programs are sequential and thus provide a better baseline than the
``sequential'' run time of LM programs, which includes extra code for managing
synchronization between multiple (inexistent) threads.

In order to make our comparison more interesting, we also provide comparisons to
the Python language and other relevant systems. Python is a \emph{scripting}
programming language that is much slower than compiled C/C++ programs and thus
is a good upper-bound in terms of performance.

The goal of the evaluation is to understand the effectiveness of our compilation
strategy and the effectiveness of our dynamic indexing algorithms, including the
data structures (hash tables) which are used to store index logical facts. The
LM programs used in the experiments are the following:

\begin{itemize}
   \item Multiple Single Shortest Distance (MSSD): a program that computes the
      shortest distance from a subset of nodes of the graph to the all the nodes
      in the graph. A modified version is presented in
      Section~\ref{section:coord:rationale}.

      
    \item MiniMax: the AI algorithm for selecting the best player move in a
       Tic-Tac-Toe game. The initial board was augmented in order to provide a
       longer running benchmark. Program is presented in
       Section~\ref{section:coord:minimax}.

   \item Belief Propagation: a machine learning to denoise images. Program is
      explained in Section~\ref{sec:coordination:bp}.

    \item Heat Transfer: an asynchronous program that performs transfer of heat
       between nodes. Program is explained in Section~\ref{section:coord:ht}.

   \item N-Queens: the classic puzzle for placing queens on a chess board so
      that no two queens threaten each other. Program is explained in
      Section~\ref{section:coord:nqueens}.

\end{itemize}

Table~\ref{table:implementation:absolute} presents the comparison between LM and
sequential C++ programs. Comparisons to other systems are shown under the
\textbf{Other} column. Since we also want to assess the VM's scalability for
different program sizes, we use different datasets in several programs.

\begin{table}[ht]
   \begin{center}
      \input{experiments/absolute/runtime}
   \end{center}

   \caption{Experimental results comparing different programs against
      hand-written versions in C++. For the C++ programs, we show the execution
      time in seconds (\textbf{C++ Time (s)}). For the other approaches, we show
      the overhead ratio compared with the corresponding C++ program. The
      overhead numbers (\textbf{lower is better}) are computed by dividing the
   execution time of the approach on that column by the execution time of the
similar hand-written C++ program.}

   \label{table:implementation:absolute}
\end{table}

For the MSSD program, we have used four datasets, which we describe as follows:

\begin{itemize}
   \item US 500 Airports~\cite{usairports,tnet}, a graph of the 500 top airports in the US with around
      5000 connections. The shortest distance is calculated for all nodes;
      
   \item OCLinks~\cite{tnet,oclinks}, a facebook-like social network with around 2000 nodes and 20000 edges. The shortest
      distance is calculated for 33\% of the nodes;

   \item US Power Grid~\cite{tnet,uspowergrid}, the power grid for western US with around 5000
      nodes and 13000 edges. The shortest distance is calculated for 20\% of the
      nodes;

   \item Email~\cite{snapnets}, a larger graph with 265000 nodes and 420000
      edges. The shortest distance was calculated for 100 nodes.

\end{itemize}

The C++'s MSSD programs applies the Dijkstra algorithm for each node we want to
compute the shortest distance from. While the Dijkstra algorithm has a better
complexity than the algorithm used in LM's algorithm, LM's algorithm is able to
process distances from multiple sources at the same time. Our experiments show
that the C++ program effectively beats LM's version by a large margin, but that
gap is reduced as the number of nodes increases. The C++ program needs to
initialize the Dijkstra algorithm for each source node, dropping its absolute
perform to just half of LM's performance. These results are also affected by the
increased locality and indexing used in LM's VM, which is shown to scale well in
our experiments. Python is much slower than LM but the gap between C++ is also
decreased as the graph gets larger.

The C++ version of the MiniMax program uses a single recursive function that
updates a single state as it is recursively called to generate the best score
and move. The LM version is seven times slower due to the costs of creating new
nodes using the exists construct and the large memory requirements as shown
next. In Chapter~\ref{chapter:coordination} we will show how to improve the the
space complexity of the MiniMax program and the corresponding run time.  Another
interesting aspect of the MiniMax program is that it does not use any persistent
predicate and therefore does not use array data structures for managing facts,
which have show to improve the run time of several programs in previous
experiments.

The Belief Propagation experiment is the program where LM performs the best when
compared to the C++ version. We found out that the mathematical operations
required to update the nodes belief values are expensive and make up a huge part
of the total computation time. This is clearly shown in the low overhead
numbers. We also compared our performance against the GraphLab and LM is only
slightly slower, which is also a point in LM's favour.

The Heat Transfer program behaves somewhat like Belief Propagation but LM is
almost an order of magnitude slower than the C++ version. We think this is
because the heat transfer computation is very small which tends to exacerbate
slower and repeated fact derivations on different nodes that are used to
propagate new heat values.

The LM's N-Queens programs shows some scalability issues since the overhead
ratio increases as the size of the problem increases. However, the same
behavior is seen in the Python program. The C++ program uses a backtracking
strategy to try out all the possibilities and uses a vector to store placements.
Since there is only at most $N$ (size of the board) vectors at the same time, it
shows better behavior than all the other programs. However, we should note that a
3-fold slowdown is a fairly good trade-off for a higher-level program that runs
faster than the C++ version when using 4 to 5 threads.

From these results, it is possible to conclude that LM's virtual machine offers
a decent performance when compared to hand-written C++ programs. We think these
results originate from four main aspects of our system: efficient indexing,
data structures with good locality such as array data structures for persistent
facts, improved memory locality from the memory allocator, and an efficient LM
to C++ compilation scheme. As noted in~\cite{cost}, scalability should not be
the sole focus of a parallel/distributed system such as LM. We have shown that
LM programs run reasonably fast and we will show next that they also scale well.

\subsubsection{Memory usage}

To complete our comparison against the C++ programs, we have measured and
compared the average memory used by both systems.
Table~\ref{table:implementation:mem} presents the memory statistics for LM
programs while Table~\ref{table:implementation:cmem} presents statistics for the
C++ programs.

\begin{table}[ht]
   \begin{center}
      \input{experiments/mem/mem}
   \end{center}
   \caption{Memory statistics for LM programs. The meaning of each column is as
      follows: column \textbf{Average} represents the average memory use of the
      program; \textbf{Final} represents the memory usage after the program
      completes; \textbf{Malloc} represents the number of \code{malloc}
   operations requested to the operating system by the VM's memory allocator;
   \textbf{\# Facts} represents the number of facts in the database after the
   program completes; \textbf{Each} is the result of dividing \textbf{Final} by
   \textbf{\# Facts} and represents the average memory required per fact.}
   \label{table:implementation:mem}
\end{table}

The MSSD program shows that LM's VM requires 2 to 5 times more memory than the
corresponding C++ program. The ratio is larger when the dataset used is smaller
which is understandable due to the extra data structures required by the VM
(namely the node data structure). In terms of average memory per fact, we see
that the MSSD requires on average 60B, which is not bad considering that, in
reality, each fact for this particular program requires around 32B. This
indicates that all those extra data structures represent a relatively minor
overhead.

\begin{table}[ht]
   \begin{center}
      \input{experiments/mem/c-mem}
   \end{center}
   \caption{Average memory usage of each C++ program.}
   \label{table:implementation:cmem}
\end{table}


When the MiniMax program completes, there is only a single fact on the database
that indicates the best player move. The MiniMax program is also the only
program in this experiment that dynamically generates a (tree) graph, which is
destroyed once the best move is found. The garbage collector implemented the VM
that collects empty nodes, is able to delete all those nodes since the
\textbf{Final} memory usage is much smaller than the \textbf{Average} statistic.
However, because the garbage collector retains a small number of freed nodes
that may be reused later, the average size per fact is 15.50KB, which also
includes those freed nodes. Finally, the memory usage of the C++ program is much
better because the C++ program uses function calls to represent the tree
structure of the MiniMax algorithm.

The Belief Propagation program shows that LM's VM has a much higher resource
usage than the corresponding C++ version. This is because the nodes in the LM's
program keep a copy of the belief values of neighbor nodes, while the C++
program performs uses shared memory and the stack to read and compute the
neighbors belief values. Interestingly, this issue does not happen in the Heat
Transfer program, where heat values are shared between nodes, reducing the need
to keep facts with unique lists around. Notably, the C++ memory usage is not
much smaller than LM's VM.

Finally, for the N-Queens program it is possible to immediately understand whey
there may be scalability issues when using larger data sets because the memory
usage increases significantly when using larger boards. On the positive side,
the average memory usage per fact remains the same for all data sets. In respect
to the C++ program, it is expected that it should consume almost no memory
because it uses the stack to compute the problem solutions.

\subsubsection{Indexing and data structures}

We now evaluate the impact of our dynamic indexing algorithm and related data
structures. For this, we have rerun the previous experiments and compared the
results against the optimized version.
Table~\ref{table:implementation:compare_absolute} shows the comparison between
the optimized version of the VM and the version of the VM with indexing
disabled. From column \textbf{Run Time} shows that the MSSD program benefits
from indexing because the unoptimized version is around 25 to 75 times slower
than the version with indexing enabled. Since MSSD computes the shortest
distance to multiple nodes, its rules require searching for the shortest
distance facts of arbitrary nodes. All the other programs do not require index
but also do not display any significant slowdown from using dynamic indexing. In
terms of memory usage, the version with indexing uses slightly more memory,
especially for MSSD program, where the US Power Grid dataset requires 50\% more
memory due to the existence of hash tables used for supporting indexing.

\begin{table}[ht]
   \begin{center}
      \input{experiments/absolute/compare-no-indexing}
   \end{center}
   \caption{Measuring the impact of dynamic indexing and related database data
      structures. Column \textbf{Run Time} shows the slow down ratio of the
      unoptimized version (numbers greater than 1 show indexing improvements).
      Column \textbf{Average Memory} is the result of dividing the average
      memory of the optimized version by the unoptimized version (large numbers
      indicate that more memory is needed when using indexing mechanisms).}
   \label{table:implementation:compare_absolute}
\end{table}

\subsubsection{Array data structures}

Another important implementation detail is the use of array data structures for
storing persistent facts that are not derived by rule derivation but only exist
as initial facts. These cases are detected by the compiler and allow the VM to
improve memory locality and reduce memory usage by packing persistent facts in a
contiguous memory area.

\begin{table}[ht]
   \begin{center}
      \input{experiments/absolute/compare-no-arrays}
   \end{center}

   \caption{Measuring the impact of using array data structures for persistent
      facts. Column \textbf{Run Time} shows the speedups obtained by using
      arrays. Column \textbf{Average Memory} is the result of dividing the
      average memory of the programs using arrays by the version without them
      (e.g., numbers show memory usage reduction when using array data
   structures).}

   \label{table:implementation:compare_arrays}
\end{table}


\subsection{Scalability}

\subsubsection{Thread allocator evaluation}

